{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift = 4320\n",
    "shift_lbp = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hog_features = 'C:\\\\Users\\\\rafae\\\\Desktop\\\\Coleta\\\\features\\\\features_hog_*.csv'\n",
    "lbp_features = 'C:\\\\Users\\\\rafae\\\\Desktop\\\\Coleta\\\\features\\\\features_lbp_*.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513\n",
      "513\n"
     ]
    }
   ],
   "source": [
    "hog_files_list = glob.glob(hog_features)\n",
    "print(len(hog_files_list))\n",
    "\n",
    "lbp_files_list = glob.glob(lbp_features)\n",
    "print(len(lbp_files_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read features\n",
    "frames = [pd.read_csv(f, header=0) for f in hog_files_list ]\n",
    "len(frames)\n",
    "\n",
    "# read features\n",
    "lbp = [pd.read_csv(f, header=0) for f in lbp_files_list ]\n",
    "len(lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = pd.concat(frames)\n",
    "ds_lbp = pd.concat(lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7680, 17282) (7680, 106)\n"
     ]
    }
   ],
   "source": [
    "print(ds.shape, ds_lbp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17272</th>\n",
       "      <th>17273</th>\n",
       "      <th>17274</th>\n",
       "      <th>17275</th>\n",
       "      <th>17276</th>\n",
       "      <th>17277</th>\n",
       "      <th>17278</th>\n",
       "      <th>17279</th>\n",
       "      <th>17280</th>\n",
       "      <th>17281</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071793</td>\n",
       "      <td>0.090339</td>\n",
       "      <td>0.127822</td>\n",
       "      <td>0.127822</td>\n",
       "      <td>0.042653</td>\n",
       "      <td>0.053141</td>\n",
       "      <td>0.059538</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.019839</td>\n",
       "      <td>0.127822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.024254</td>\n",
       "      <td>0.051084</td>\n",
       "      <td>0.053452</td>\n",
       "      <td>0.014108</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.119957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103166</td>\n",
       "      <td>0.037546</td>\n",
       "      <td>0.044686</td>\n",
       "      <td>0.122575</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.104095</td>\n",
       "      <td>0.087389</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.017647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.091092</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.123109</td>\n",
       "      <td>0.038147</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.050142</td>\n",
       "      <td>0.042432</td>\n",
       "      <td>0.028560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052366</td>\n",
       "      <td>0.038015</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.061695</td>\n",
       "      <td>0.040908</td>\n",
       "      <td>0.070168</td>\n",
       "      <td>0.032586</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.023819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1   2   3   4   5   6   7   8   9    ...        17272     17273  \\\n",
       "0  1  p002 NaN NaN NaN NaN NaN NaN NaN NaN    ...     0.071793  0.090339   \n",
       "1  1  p002 NaN NaN NaN NaN NaN NaN NaN NaN    ...     0.069514  0.119957   \n",
       "2  1  p002 NaN NaN NaN NaN NaN NaN NaN NaN    ...     0.103166  0.037546   \n",
       "3  1  p002 NaN NaN NaN NaN NaN NaN NaN NaN    ...     0.132490  0.091092   \n",
       "4  1  p002 NaN NaN NaN NaN NaN NaN NaN NaN    ...     0.052366  0.038015   \n",
       "\n",
       "      17274     17275     17276     17277     17278     17279     17280  \\\n",
       "0  0.127822  0.127822  0.042653  0.053141  0.059538  0.003019  0.019839   \n",
       "1  0.119957  0.119957  0.024254  0.051084  0.053452  0.014108  0.010533   \n",
       "2  0.044686  0.122575  0.033838  0.104095  0.087389  0.003405  0.009884   \n",
       "3  0.132490  0.123109  0.038147  0.132490  0.132490  0.050142  0.042432   \n",
       "4  0.034714  0.061695  0.040908  0.070168  0.032586  0.004734  0.009425   \n",
       "\n",
       "      17281  \n",
       "0  0.127822  \n",
       "1  0.119957  \n",
       "2  0.017647  \n",
       "3  0.028560  \n",
       "4  0.023819  \n",
       "\n",
       "[5 rows x 17282 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.014532</td>\n",
       "      <td>0.015844</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>0.009943</td>\n",
       "      <td>0.016499</td>\n",
       "      <td>0.015188</td>\n",
       "      <td>0.017920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018029</td>\n",
       "      <td>0.021416</td>\n",
       "      <td>0.011691</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.009943</td>\n",
       "      <td>0.013221</td>\n",
       "      <td>0.014751</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>0.235468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.014532</td>\n",
       "      <td>0.013003</td>\n",
       "      <td>0.011910</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>0.011473</td>\n",
       "      <td>0.011910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018466</td>\n",
       "      <td>0.019777</td>\n",
       "      <td>0.011145</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>0.011254</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.010927</td>\n",
       "      <td>0.015188</td>\n",
       "      <td>0.048733</td>\n",
       "      <td>0.236233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.014969</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.014423</td>\n",
       "      <td>0.015406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.014969</td>\n",
       "      <td>0.050153</td>\n",
       "      <td>0.231206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.022509</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.013658</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.018138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019122</td>\n",
       "      <td>0.019777</td>\n",
       "      <td>0.010271</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.011145</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>0.013330</td>\n",
       "      <td>0.052557</td>\n",
       "      <td>0.228475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.015406</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.011254</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.015188</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.020323</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>0.015079</td>\n",
       "      <td>0.049934</td>\n",
       "      <td>0.220061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1         2         3         4         5         6         7  \\\n",
       "0  1  p002  0.020651  0.014532  0.015844  0.012784  0.009943  0.016499   \n",
       "1  1  p002  0.017373  0.017045  0.014532  0.013003  0.011910  0.012128   \n",
       "2  1  p002  0.020542  0.014969  0.011582  0.013986  0.012566  0.014095   \n",
       "3  1  p002  0.022509  0.014095  0.013658  0.012456  0.011364  0.011801   \n",
       "4  1  p002  0.019012  0.011364  0.015406  0.012675  0.011254  0.014095   \n",
       "\n",
       "          8         9    ...           96        97        98        99  \\\n",
       "0  0.015188  0.017920    ...     0.018029  0.021416  0.011691  0.012019   \n",
       "1  0.011473  0.011910    ...     0.018466  0.019777  0.011145  0.011582   \n",
       "2  0.014423  0.015406    ...     0.017373  0.018684  0.010490  0.012238   \n",
       "3  0.010380  0.018138    ...     0.019122  0.019777  0.010271  0.012456   \n",
       "4  0.015188  0.017045    ...     0.017373  0.020323  0.012675  0.011364   \n",
       "\n",
       "        100       101       102       103       104       105  \n",
       "0  0.010599  0.009943  0.013221  0.014751  0.045892  0.235468  \n",
       "1  0.011254  0.010599  0.010927  0.015188  0.048733  0.236233  \n",
       "2  0.012456  0.010599  0.012566  0.014969  0.050153  0.231206  \n",
       "3  0.011145  0.010052  0.014642  0.013330  0.052557  0.228475  \n",
       "4  0.012893  0.012019  0.012893  0.015079  0.049934  0.220061  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_lbp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    6105\n",
      "True     1575\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# convert points do binary Eyes ON or OFF Road\n",
    "on_road_points = [13, 14, 16, 17]\n",
    "on_off_road_bit = np.where(ds['0'].isin(on_road_points), 1,0)\n",
    "print(ds['0'].isin(on_road_points).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yData = on_off_road_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xData = pd.concat([ds.iloc[:,2+shift:2+shift+shift], ds_lbp.iloc[:,2:2+shift_lbp]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7680, 4346)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yData[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7680,) (7680, 4346) <class 'numpy.ndarray'> <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(yData.shape, xData.shape, type(yData), type(xData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    plt.yticks(tick_marks)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# Compute confusion matrix\n",
    "def plot_confusion(yTest, yTestPred, name):\n",
    "    cm = confusion_matrix(yTest, yTestPred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Normalize the confusion matrix by row (i.e by the number of samples in each class)\n",
    "    cm_normalized = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis])*100\n",
    "    print('Classification report')\n",
    "    print(classification_report(yTest, yTestPred))\n",
    "    print('Normalized confusion matrix')\n",
    "    print(cm_normalized)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix (%s)' % (name))\n",
    "\n",
    "    plt.show()\n",
    "    # plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer,precision_recall_fscore_support\n",
    "\n",
    "def search(X_train, X_test, y_train, y_test, group_data_train):\n",
    "    \n",
    "    # normalize data\n",
    "    print(\"Normalizing data!\")\n",
    "    stdScale = preprocessing.StandardScaler().fit(X_train)\n",
    "    xTrain = stdScale.transform(X_train)\n",
    "    xTest = stdScale.transform(X_test)\n",
    "    \n",
    "    print(\"Grid Search Classifiers!\")\n",
    "    \n",
    "    knc = KNeighborsClassifier()\n",
    "    svc = SVC()\n",
    "    rfc = RandomForestClassifier()\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "    clf1 = SVC()\n",
    "    clf2 = RandomForestClassifier(random_state=1)\n",
    "    clf3 = GaussianNB()\n",
    "    vt = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "    kncp = [{'n_neighbors': [3, 5, 7, 10],\n",
    "             'weights': ['uniform','distance'],\n",
    "              'algorithm': ['auto','kd_tree']}]\n",
    "    svcp = [{'kernel': ['rbf'], #{'kernel': ['rbf','linear'], \n",
    "             'class_weight':['balanced'],\n",
    "             'gamma': ['auto',0.1, 0.001, 0.0001], #'gamma': [0.0001],#\n",
    "             'C': [0.001, 0.01, 0.1, 1.0, 1, 10, 50, 100]}]#'C': [1000]}]#\n",
    "    rfcp = [{'n_estimators': [10, 20, 50, 100,200], \n",
    "            'max_features': ['auto', 'log2'],\n",
    "            'max_depth': [None],\n",
    "            'bootstrap': [True, False],\n",
    "            'criterion': [\"gini\", \"entropy\"]}]\n",
    "    gbp = [{#'loss' : ['deviance', 'exponential'],\n",
    "           'n_estimators': [10, 50,100, 200],\n",
    "           'learning_rate': [0.001, 0.01, 0.1, 1.0,10],\n",
    "           'max_features': ['auto', 'log2'],\n",
    "           'max_depth' : [3,5,10, 100]\n",
    "            }]\n",
    "           #'min_impurity_decrease': [0.0]}]#, 0.1]}]\n",
    "    vtp = [{'svc__C': [1.0, 100.0], \n",
    "            'rf__n_estimators': [20, 200],}]\n",
    "   \n",
    "    classifiers = [('kNN', knc, kncp),                                 \n",
    "                    ('Support Vector', svc, svcp),\n",
    "                    ('Random Forest', rfc, rfcp),\n",
    "                    ('Gradient Boosting', gb, gbp),\n",
    "                    ('Vooting', vt, vtp)\n",
    "    ]\n",
    "    \n",
    "    for name, classifier, params in classifiers:\n",
    "        print(name)\n",
    "        clf = GridSearchCV(classifier, params,n_jobs=4, cv=5, scoring=['f1_weighted','accuracy','precision_weighted', 'recall_weighted'], refit='f1_weighted' , verbose = 10)\n",
    "\n",
    "        clf.fit(X_train, y_train, groups=group_data_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print(clf.best_score_)\n",
    "        print()\n",
    "        print(clf.cv_results_.keys())\n",
    "        means = clf.cv_results_['mean_test_accuracy']\n",
    "        stds = clf.cv_results_['std_test_accuracy']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        yTrue, yPred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(yTrue, yPred))\n",
    "        plot_confusion(yTrue, yPred, name)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(yData)\n",
    "print(le.classes_)\n",
    "yDataBin = le.transform(yData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (5131,) (2549,)\n",
      "TRAIN: [   0    1    2 ..., 7677 7678 7679] TEST: [ 570  571  572 ..., 7407 7408 7409]\n",
      "['p002' 'p003' 'p005' 'p006' 'p008' 'p009' 'p011' 'p012' 'p013' 'p015'\n",
      " 'p019' 'p020' 'p021' 'p022' 'p023' 'p024' 'p026' 'p027' 'p029' 'p033']\n",
      "['p004' 'p007' 'p014' 'p016' 'p025' 'p028' 'p030' 'p031' 'p032']\n",
      "0    4081\n",
      "1    1050\n",
      "Name: 0, dtype: int64\n",
      "0    2024\n",
      "1     525\n",
      "Name: 0, dtype: int64\n",
      "\n",
      "\n",
      "Normalizing data!\n",
      "Grid Search Classifiers!\n",
      "kNN\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed: 82.9min\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed: 124.6min\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed: 207.3min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed: 251.2min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed: 375.8min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 459.8min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed: 582.9min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed: 669.4min\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed: 845.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "\n",
      "Grid scores on development set:\n",
      "0.72709591969\n",
      "\n",
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_algorithm', 'param_n_neighbors', 'param_weights', 'params', 'split0_test_f1_weighted', 'split1_test_f1_weighted', 'split2_test_f1_weighted', 'split3_test_f1_weighted', 'split4_test_f1_weighted', 'mean_test_f1_weighted', 'std_test_f1_weighted', 'rank_test_f1_weighted', 'split0_train_f1_weighted', 'split1_train_f1_weighted', 'split2_train_f1_weighted', 'split3_train_f1_weighted', 'split4_train_f1_weighted', 'mean_train_f1_weighted', 'std_train_f1_weighted', 'split0_test_accuracy', 'split1_test_accuracy', 'split2_test_accuracy', 'split3_test_accuracy', 'split4_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy', 'split0_train_accuracy', 'split1_train_accuracy', 'split2_train_accuracy', 'split3_train_accuracy', 'split4_train_accuracy', 'mean_train_accuracy', 'std_train_accuracy', 'split0_test_precision_weighted', 'split1_test_precision_weighted', 'split2_test_precision_weighted', 'split3_test_precision_weighted', 'split4_test_precision_weighted', 'mean_test_precision_weighted', 'std_test_precision_weighted', 'rank_test_precision_weighted', 'split0_train_precision_weighted', 'split1_train_precision_weighted', 'split2_train_precision_weighted', 'split3_train_precision_weighted', 'split4_train_precision_weighted', 'mean_train_precision_weighted', 'std_train_precision_weighted', 'split0_test_recall_weighted', 'split1_test_recall_weighted', 'split2_test_recall_weighted', 'split3_test_recall_weighted', 'split4_test_recall_weighted', 'mean_test_recall_weighted', 'std_test_recall_weighted', 'rank_test_recall_weighted', 'split0_train_recall_weighted', 'split1_train_recall_weighted', 'split2_train_recall_weighted', 'split3_train_recall_weighted', 'split4_train_recall_weighted', 'mean_train_recall_weighted', 'std_train_recall_weighted'])\n",
      "0.715 (+/-0.157) for {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.715 (+/-0.157) for {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.711 (+/-0.152) for {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.711 (+/-0.152) for {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.712 (+/-0.145) for {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.712 (+/-0.145) for {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "0.723 (+/-0.131) for {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "0.716 (+/-0.148) for {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "0.715 (+/-0.157) for {'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.715 (+/-0.157) for {'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.711 (+/-0.152) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.711 (+/-0.152) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.712 (+/-0.145) for {'algorithm': 'kd_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.712 (+/-0.145) for {'algorithm': 'kd_tree', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "0.723 (+/-0.131) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "0.716 (+/-0.148) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.88      0.87      2024\n",
      "          1       0.50      0.47      0.49       525\n",
      "\n",
      "avg / total       0.79      0.79      0.79      2549\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.88      0.87      2024\n",
      "          1       0.50      0.47      0.49       525\n",
      "\n",
      "avg / total       0.79      0.79      0.79      2549\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[ 87.55  12.45]\n",
      " [ 52.57  47.43]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAFgCAYAAACBlHNxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAH/VJREFUeJzt3Xm8XGWd5/HPNwFZw2YwBgFxARSdZou0+6AgL1AQxlEE\nFUODosyI2DYibt2u3Uy79Lj12LFRYiu0cWFARBGjqCgiYZUdQSJgSAi7bEr4zh/nuVC5c29V5dat\ne+45+b7zqtetOufUc566t/KrX/2e55wj20RERH1m1N2BiIi1XQJxRETNEogjImqWQBwRUbME4oiI\nmiUQR0TULIE4IqJmCcQRETVLII6IqNk6dXcgImIYZm7yVPuRByf8fD94+9m2953ELo0rgTgiWsmP\nPMh6Ox484ec/dOkXZ09id7pKII6IlhKoGdXXBOKIaCcBUt296EsCcUS0V0My4mb0MiKixZIRR0R7\npTQREVGnDNZFRNQvGXFERI1EYzLiZvQyIqLFkhFHREsppYmIiNo1pDSRQBwR7dWQjLgZHxcRES2W\njDgiWirziCMi6pWT/kRETAMNyYib0cuIiBZLRhwRLdWcGnEzerkWkfRhSV8v97eV9CdJMyd5HzdJ\n2nsy2+xjn0dLWl5ezxMHaOdPkp4+mX2ri6QrJe05wefuJGmJVBVBh/03lTRH0tWS1hvWPoZihiZ+\nm8puTunepoHyhl0haaOOZW+RdG6N3RqT7T/Y3tj2qrr7MghJ6wKfAfYpr+eOibZVnn/j5PVu8kk6\nWdLHe21n+zm2z53gbj4GfMq2++hPz/e8JEv6rfR4Cinp45JOLn1dDvwUOGqC/Z16I+eamOhtCq11\ngbiYCRw7aCOqrK2/wzUxB1gfuLLujkwHkgYqCUqaC7wM+L9r8LR+3vNbAYd0Wf8N4G1rsM/6SRO/\nTaG1NYh8EjhO0mZjrZT0QkkXSrqn/Hxhx7pzJX1C0i+BB4Cnl2Ufl/Sr8tX5e5KeKOkbku4tbWzX\n0cZnJd1c1l0k6SXj9GO7kqmsI+kFpe2R20OSbirbzZB0gqQbJN0haZGkLTraOUzS0rLuA91+MZI2\nkPTpsv09ks6TtEFZ9+rydfru8pqf3fG8myQdJ+ny8rxvSlpf0g7AtWWzuyX9pPN1jfq9vqXcf6ak\nn5V2Vkr6Zsd2lvTMcn9TSV+TdHvp7wdHPhglHV76/ilJd0n6vaT9urzumyS9p/T/fkknla/jP5B0\nn6QfS9q8Y/tvSbqt9PHnkp5Tlh8FvBE4fuS90NH+eyVdDtxf/qaPlRMknSXp0x3t/6ekr4zT3VcA\nF9t+aJzX8uzyeg/tWNz1PV/8M/CRLh8UF1C935/apY2YgLU1EC8BzgWOG72iBLDvA58Dnkj1lfr7\nWr2ueRjVV7RZwNKy7JCy/CnAM4Dzga8CWwBXA//Q8fwLgV3KulOAb0lav1uHbZ9fvpZvDGxO9Z/i\n1LL6GOAg4L9SZTV3AV8sr2cn4P+Uvm1VXtPWXXb1KWB34IWlf8cDj5aAeirwLmBL4Czge5Ke0PHc\ng4F9gacBfwUcbvs64Dll/Wa2X97tdRYfA35UXufWwOfH2e7zwKbA08trfzPwNx3r/5rqQ2A2VZA5\nSeqa6vx3qiC3A3AA8APg/eX1zgDe2bHtD4DtgScBF1Nli9heUO7/c/l7HdDxnEOBV1H9Hh4Zte8j\ngMMkvVzSG4E9GD+D/S88/uG2Gkm7AWcDx9g+tWPVuO/5Dt8F7gUOH2tl6fPvgJ27tDGNKKWJBvh7\n4BhJW45a/irgetv/YfuR8ma+huo/5oiTbV9Z1v+lLPuq7Rts30P1n/QG2z8ub95vAbuOPNn2123f\nUZ7/aWA9YMc16PvngPuAkez27cAHbN9i+2Hgw8BrS2bzWuBM2z8v6z4EPDpWoyWbPAI41vattlfZ\n/lV53uuB79s+p7zmTwEbUAXsx/pl+4+27wS+R/VhMxF/AZ4KbGX7IdvnjdHXmVQffu+zfZ/tm4BP\nU33gjFhq+8ulxr4QmEtVJhnP520vt30r8AvgAtuXlMzzNFb/G36l7Hfk972zpE17vK7P2b7Z9oOj\nV9i+DTi69POzwJtt3zdOO5tR/f1HewlwRnnumWOsH+89/1g3qN4fHxr1AdvpvrL/ZkhpYnqzfQVw\nJnDCqFVb8XiWO2IpVaY74uYxmlzecf/BMR5vPPKgfIW/unytvZsqq5vdT78lvQ3YE3iD7ZGA+lTg\ntFIyuJsqA19FFXS26uyv7fuB8QbLZlPVcm8YY91qv5ey75tZ/fdyW8f9B+h4zWvoeKqhlt+UUsgR\n4/R1XVb/W43+Oz3WH9sPlLvd+tTX31DSTEknllLQvcBNHX3qZqz3TafvUdVyrx3rw6fDXVTfxkZ7\nO/Cr8QYAu7znO7c5C7iF8WvBs4C7u/RteklG3Aj/ALyV1f/z/pEqsHXaFri143HPkerxqKoHH0/1\nNX5z25sB91AFnn6e+zHgQNv3dqy6GdjP9mYdt/VLZrcM2KajjQ2pyhNjWQk8RFVaGW2130v5ir8N\nq/9e+nV/+blhx7Inj9yxfZvtt9reiiog/OtIXXhUX0cy5xGj/07D8gbgQGBvqg/R7crykb/heO+P\nXu+bT1B9iM4dVd8d7XKq8slobwe2lfQvXZ471nt+tA9QlWQ6/z4jg4zPBC7r8tyYgLU6ENv+HfBN\nVq/9nQXsIOkNZUDl9cBOVJnEZJgFPALcDqwj6e+BTXo9SdI2wCKqr53XjVr9JeATI4MokraUdGBZ\n921gf0kvLl83P8o4f/eS5X4F+IykrUrm9wJVc0cXAa+StJeq6Wh/BzwM/GqNXn21n9upAuabyj6O\noCP4S3qdpJE69l1UAezRUW2sKn36hKRZ5bW/G/j6mvZnAmZRvfY7qILVP45av5yqbt03SS+lqm+/\nGZgPfF7SeMHyHGC3McYV7qOq0b9U0oljPXGc9/zobc4Frij96LQHcJPt0d8Yp6dByhIpTUy5jwKP\nza8sc1z3pwo0d1Blr/vbXjlJ+zsb+CFwHdVX6Yfo/ZUVYC+qUsO39fjMiZHpYJ+lqg3+SNJ9wK+p\nBqqwfSXwP6kGBZdRBbZbuuznOOC3VAOKdwL/C5hh+1rgTVQDZCupauYH2P5zn697tLcC76H6HT+H\n1QP684ALJP2pvK5jx5k7fAxVdn0jcF55jePNNJhMX6P6290KXEX1++50ErBTKRX1nGImaZPS5jtK\nbf4XpY2vjjW4WOb0/oQqKx+97m6qAcf9JH1snF2u9p4fxwepBms7vZHqQ785GlKaUB/zwSNimimz\nYRYCe/RzUMck7O9JwM+AXcebNjfdzNh0G6/3wndP+PkP/fDdF9me120bSX8LvIXqW9tvqb7VbEj1\nrWM7qvGDg23f1bWvE+5lRNTG9lW2nzcVQbjsb4XtZzclCFeGO32tlI7eCcyz/VyqgdZDqAZDF9ve\nHlhMl8HREQnEERETtw6wQRnI3JBqUPtAqm8rlJ8H9WokgTgi2muwwbrZqk6sNHJb7TwbZVbSp4A/\nUI2/3GP7R8Ac28vKZrfRfe46kNNgRkRbjZz0Z+JWdqsRl0PeD6Q6kvRuqiNk39S5jW1L6lk+SiCO\niJYa+vmI9wZ+X6ZjIum7VEeaLpc01/YyVSdoWtGroWkViLXOBtYTxjpgKNYmuz5727q7ENPA0qU3\nsXLlyul80bk/AM8vB0k9SDXFdAnVlMr5wInl5+m9GppegfgJs1hvx4Pr7kbU7JcXfKHuLsQ08KK/\n7jpzrD9DPDDD9gWSvk110qdHgEuABVSHwi+SdCTVfPOeQW1aBeKIiEk15AMzbP8Dq59ZEaqjLvda\nk3YSiCOivab4UOWJyvS1iIiaJSOOiHZSc67inEAcEe3VkNJEAnFEtFb3K2NNHwnEEdFKojmBuBkF\nlIiIFktGHBHtJPq4ANn0kEAcES2lxpQmEogjorWaEohTI46IqFky4ohoraZkxAnEEdFaCcQREXXK\nrImIiHqpQbMmMlgXEVGzZMQR0VpNyYgTiCOitRKIIyJq1pRAnBpxRETNkhFHRDtl+lpERP2aUppI\nII6IVso84oiI6Fsy4ohoraZkxAnEEdFezYjDCcQR0VJKRhwRUbumBOIM1kVE1CwZcUS0VlMy4gTi\niGilJs0jTiCOiPZqRhxOjTgiom7JiCOinTJ9LSKifk0JxClNRERrSZrwrY+2d5R0acftXknvkrSF\npHMkXV9+bt6rrQTiiGgvDXDrwfa1tnexvQuwO/AAcBpwArDY9vbA4vK4qwTiiIjB7QXcYHspcCCw\nsCxfCBzU68mpEUdEaw1YI54taUnH4wW2F4yz7SHAqeX+HNvLyv3bgDm9dpRAHBGt1G+tt4uVtuf1\nsZ8nAK8G3jd6nW1Lcq82EogjorWmaNbEfsDFtpeXx8slzbW9TNJcYEWvBlIjjogYzKE8XpYAOAOY\nX+7PB07v1UAy4ohorWFnxJI2Al4BvK1j8YnAIklHAkuBg3u1k0AcEe015MqE7fuBJ45adgfVLIq+\nJRBHRGvlyLqIiOhLMuKIaKec9Cciol4CGhKHE4gjoq1yhY6IiNo1JA5nsC4iom7JiCOitVKaiIio\nk5pTmkggjohWEjBjRjMicWrEERE1S0YcEa2V0kRERM0yWBcRUacGDdYNtUYsaV9J10r6naSeVzKN\niJgs1SHOmvBtKg0tEEuaCXyR6jIiOwGHStppWPuLiGiqYZYm9gB+Z/tGAEn/SXWZ6auGuM+IiKI5\n55oYZmniKcDNHY9vKcsiIqaENPHbVKp9sE7SUcBRAKy7cb2diYhWSUYMtwLbdDzeuixbje0FtufZ\nnqd1NhhidyIipqdhBuILge0lPU3SE4BDqC4zHRExfAOUJVpTmrD9iKR3AGcDM4Gv2L5yWPuLiOg0\nMn2tCYZaI7Z9FnDWMPcRETGehsThnPQnIqJutc+aiIgYlpQmIiJq1pA4nEAcES2lZMQREbWqZk3U\n3Yv+ZLAuIqJmyYgjoqWac9KfBOKIaK2GxOEE4ohor6ZkxKkRR0TULBlxRLRTg65Zl0AcEa3UpJP+\npDQREa017IuHStpM0rclXSPpakkvkLSFpHMkXV9+bt6rnQTiiGitKTgf8WeBH9p+FrAzcDVwArDY\n9vbA4vK4qwTiiIgJkLQp8FLgJADbf7Z9N9VFkheWzRYCB/VqKzXiiGitAWvEsyUt6Xi8wPaCjsdP\nA24HvippZ+Ai4Fhgju1lZZvbgDm9dpRAHBHtNPisiZW253VZvw6wG3CM7QskfZZRZQjbluReO0pp\nIiJaSUx8oK7PTPoW4BbbF5TH36YKzMslzQUoP1f0aiiBOCJiAmzfBtwsaceyaC/gKqqLJM8vy+YD\np/dqK6WJiGitKZhGfAzwjXKl+huBv6FKcBdJOhJYChzcq5EE4ohorRlDjsS2LwXGqiPvtSbtJBBH\nRGs15MC61IgjIuqWjDgiWkm5Zl1ERP1mNCMOJxBHRHslI46IqFlD4nAG6yIi6paMOCJaSVSHOTdB\nAnFEtFYG6yIi6rQGV9qoW2rEERE1S0YcEa3VkIQ4gTgi2kkM/6Q/kyWBOCJaqyFxODXiiIi6jZsR\nS9qk2xNt3zv53YmImDxNmTXRrTRxJWBYbUb0yGMD2w6xXxERA9HgFw+dMuMGYtvbTGVHIiImW1MG\n6/qqEUs6RNL7y/2tJe0+3G5FRAxOA9ymUs9ALOkLwMuAw8qiB4AvDbNTERFrk36mr73Q9m6SLgGw\nfWe5YmlExLTWhsG6EX+RNINqgA5JTwQeHWqvIiIGVB3QUXcv+tNPIP4i8B1gS0kfAQ4GPjLUXkVE\nDKpBJ/3pGYhtf03SRcDeZdHrbF8x3G5FRKw9+j3EeSbwF6ryRI7Gi4hGaEhC3NesiQ8ApwJbAVsD\np0h637A7FhExKJXyxERuU6mfjPjNwK62HwCQ9AngEuCfhtmxiIhBtG2wbtmo7dYpyyIiprXGD9ZJ\n+heqmvCdwJWSzi6P9wEunJruRUS0X7eMeGRmxJXA9zuW/3p43YmImDzNyIe7n/TnpKnsSETEZJKa\nc9KfnjViSc8APgHsBKw/stz2DkPsV0TEwBoSh/uaE3wy8FWqLH8/YBHwzSH2KSJirdJPIN7Q9tkA\ntm+w/UGqgBwRMa21aR7xw+WkPzdIejtwKzBruN2KiBhcU0oT/QTivwU2At5JVSveFDhimJ2KiBiU\n0NAH6yTdBNwHrAIesT1P0hZU5dvtgJuAg23f1a2dfk76c0G5ex+Pnxw+IiIqL7O9suPxCcBi2ydK\nOqE8fm+3Brod0HEa5RzEY7H9mjXsbETE1Knv4qEHAnuW+wuBc5loIAa+MCldWgNbPHlLDjj+qKne\nbUwzH/nRtXV3IaaBP9770MBtTMGgm4EfS1oF/JvtBcAc2yOngbgNmNOrkW4HdCyelG5GRNRkwHP2\nzpa0pOPxghJoO73Y9q2SngScI+mazpW2LWncysKIfs9HHBHRKGLgjHil7XndNrB9a/m5opRz9wCW\nS5pre5mkucCKXjvKSd4jIiZA0kaSZo3cpzoh2hXAGcD8stl84PRebfWdEUtaz/bDa97diIh6DPl8\nxHOA00rWvQ5wiu0fSroQWCTpSGAp1XU+u+rnXBN7ACdRzR/eVtLOwFtsHzPAC4iIGLphBmLbNwI7\nj7H8DmCvNWmrn9LE54D9gTvKTi4DXrYmO4mImGpScw5x7icQz7C9dNSyVcPoTETE2qifGvHNpTxh\nSTOBY4DrhtutiIjBtemadUdTlSe2BZYDPy7LIiKmtdac9Mf2CuCQKehLRMSkqa7i3IxI3M+siS8z\nxjknbOdY5IiY1ppyoEQ/pYkfd9xfH/hvwM3D6U5ExNqnn9LEapdFkvQfwHlD61FExCRpSGViQuea\neBp9nE0oIqJO0vBPDD9Z+qkR38XjNeIZwJ1UJzqOiJjWGhKHuwdiVYeX7Ex1nTqAR233PKVbRET0\nr2sgLufSPMv2c6eqQxERk6VNB3RcKmlX25cMvTcREZOkFfOIJa1j+xFgV+BCSTcA91O9PtvebYr6\nGBExIQ2Jw10z4t8AuwGvnqK+RESslboFYgHYvmGK+hIRMXnUjhrxlpLePd5K258ZQn8iIiaNaEYk\n7haIZwIbQ0NeSUREh2qwru5e9KdbIF5m+6NT1pOIiEnWlEDc7eREDXkJERHN1i0jXqOL30VETDdT\nfe25iRo3ENu+cyo7EhExmdpSI46IaC4154COppzAPiKitZIRR0RrNf5cExERTZYacUTENNCQhDiB\nOCLaSsxoyOEQGayLiKhZMuKIaCWR0kRERL1achrMiIhGa8r0tdSIIyJqlow4IlopNeKIiGmgKaWJ\nBOKIaK2GxOHUiCMiBiFppqRLJJ1ZHm8h6RxJ15efm/dqI4E4IlpJVAFuorc1cCxwdcfjE4DFtrcH\nFpfHXSUQR0Q7qbpCx0Rvfe1C2hp4FfDvHYsPBBaW+wuBg3q1kxpxRLTWgCXi2ZKWdDxeYHvBqG3+\nN3A8MKtj2Rzby8r924A5vXaUQBwRrVSdBnOgULzS9rxx25f2B1bYvkjSnmNtY9uS3GtHCcQRERPz\nIuDVkl4JrA9sIunrwHJJc20vkzQXWNGrodSII6K1NMCtF9vvs7217e2AQ4Cf2H4TcAYwv2w2Hzi9\nV1vJiCOitWqaR3wisEjSkcBS4OBeT0ggjoiW6n/2w6BsnwucW+7fAey1Js9PaSIiombJiCOilUYO\n6GiCBOKIaK2pKk0MKoE4IlqrGWE4gTgi2krNyYibUkKJiGitZMQR0UoZrIuImAaaUppIII6I1mpG\nGG5O5h4R0VrJiCOitRpSmRheRizpK5JWSLpiWPuIiBhPNVinCd+m0jBLEycD+w6x/YiIrqSJ36bS\n0AKx7Z8Ddw6r/YiItkiNOCJaSqgh8yZqD8SSjgKOAtho9tyaexMRbbLWD9b1y/YC2/Nsz1t/1uZ1\ndyciWqJJg3W1Z8QREUNRw6DbRA1z+tqpwPnAjpJuKddvioiIUYaWEds+dFhtR0T0oykZcUoTEdFa\nmTUREVEjATOaEYfrnzUREbG2S0YcEa2V0kRERM0yWBcRUbNkxBERNcpgXURE9C0ZcUS0VM6+FhFR\nrwadayKBOCJaqyFxODXiiIi6JSOOiFaqZk00IydOII6I1mpGGE4gjog2a0gkTo04ImICJK0v6TeS\nLpN0paSPlOVbSDpH0vXlZ89rwCUQR0RraYB/fXgYeLntnYFdgH0lPR84AVhse3tgcXncVQJxRLSW\nNPFbL678qTxct9wMHAgsLMsXAgf1aiuBOCJaSwPcgNmSlnTcjvr/2pdmSroUWAGcY/sCYI7tZWWT\n24A5vfqZwbqIaK/BButW2p7XbQPbq4BdJG0GnCbpuaPWW5J77SgZcUTEgGzfDfwU2BdYLmkuQPm5\notfzE4gjopWqEsPwBuskbVkyYSRtALwCuAY4A5hfNpsPnN6rrZQmIqKdhn/Sn7nAQkkzqZLaRbbP\nlHQ+sEjSkcBS4OBeDSUQR0RrDTMO274c2HWM5XcAe61JWylNRETULBlxRLRXQw5xTiCOiJbKFToi\nImrXkLNgJhBHRDt1HCE37WWwLiKiZsmII6K9GpISJxBHRGtlsC4iomZNGaxLjTgiombJiCOitRqS\nECcQR0RLNWj+WgJxRLRWUwbrUiOOiKhZMuKIaCXRnFkTCcQR0VoNicMJxBHRYg2JxAnEEdFaGayL\niIi+JCOOiNbKYF1ERM0aEocTiCOixRoSiVMjjoioWTLiiGil6lQTzUiJE4gjop2UwbqIiNo1JA4n\nEEdEizUkEmewLiKiZsmII6KllMG6iIi6ZbAuIqJGDbpSUmrEERF1S0YcEe3VkJQ4gTgiWiuDdRER\nNWvKYF1qxBEREyBpG0k/lXSVpCslHVuWbyHpHEnXl5+b92prWmXEd/z+qpUnv2HnpXX3o2azgZV1\ndyJql/cBPHXQBoacED8C/J3tiyXNAi6SdA5wOLDY9omSTgBOAN7braFpFYhtb1l3H+omaYnteXX3\nI+qV98EkGPJJf2wvA5aV+/dJuhp4CnAgsGfZbCFwLk0KxBERk2ugSDxb0pKOxwtsLxhzL9J2wK7A\nBcCcEqQBbgPm9NpRAnFEtJIYOCNe2c+3EkkbA98B3mX7XnXs1LYluVcbGaybfsb8xI21Tt4HDSBp\nXaog/A3b3y2Ll0uaW9bPBVb0aieBeJoZ76tPrF3yPpgcGuDWs+0q9T0JuNr2ZzpWnQHML/fnA6f3\naiuliYhorSHPI34RcBjwW0mXlmXvB04EFkk6ElgKHNyroQTiiGitYR5ZZ/s8xk+e91qTtlKaiIio\nWTLimknaEdgCWAI8antVzV2KGkmamffAJGrIIc4JxDWS9BrgH4Fby22JpJNt31tvz2KqSdrB9nW2\nVyUYT56GxOGUJupSpr28HjjS9l5UI6vbAO+VtEmtnYspJWl/4FJJpwCMBOOau9V40mC3qZRAXK9N\ngO3L/dOAM4F1gTdITTlvVAxC0kbAO4B3AX+W9HVIMJ4sGuDfVEogrontvwCfAV4j6SW2HwXOAy4F\nXlxr52LK2L4fOAI4BTgOWL8zGNfZt5g6CcT1+gXwI+AwSS+1vcr2KcBWwM71di2miu0/2v6T7ZXA\n24ANRoKxpN0kPaveHjbYMI/omEQZrKuR7YckfQMw8L7yH+5hqpOELOv65Ggl23dIehvwSUnXADOB\nl9XcrcZqSn0vgbhmtu+S9GXgKqps6CHgTbaX19uzqIvtlZIuB/YDXmH7lrr71FRNGWlJIJ4GbP8Z\n+Kmkn1cP/WjdfYr6lCs6vBLYx/Zv6+5PDF8C8TSSwZmAx74lHWD7obr70mxTP/thohKII6ahBOHB\nTcL5iKdMZk1ERNQsgTgiomYpTUREa6U0EY0gaZWkSyVdIelbkjYcoK09JZ1Z7r+6XEp8vG03k/Q/\nJrCPD0s6rt/lo7Y5WdJr12Bf20m6Yk37GNNHDnGOpnjQ9i62nwv8GXh750pV1vh9YvsM2yd22WQz\nYI0DcUTfctKfaKhfAM8smeC1kr4GXAFsI2kfSedLurhkzhsDSNpX0jWSLgZeM9KQpMMlfaHcnyPp\nNEmXldsLqS4n84ySjX+ybPceSRdKulzSRzra+oCk6ySdB+zY60VIemtp5zJJ3xmV5e8taUlpb/+y\n/UxJn+zY99sG/UVG/QY5unmqKxoJxAGApHWojuQaOYBge+BfbT8HuB/4ILC37d2oTmL/bknrA18G\nDgB2B548TvOfA35me2dgN+BK4ATghpKNv0fSPmWfewC7ALtLeqmk3YFDyrJXAs/r4+V81/bzyv6u\nBo7sWLdd2cergC+V13AkcI/t55X23yrpaX3sJ2JSZLAuNui48OEvqK5KuxWw1Pavy/LnAzsBvyxn\n53wCcD7wLOD3tq8HKCeqOWqMfbwceDM8dtDKPeXosU77lNsl5fHGVIF5FnCa7QfKPs7o4zU9V9LH\nqcofGwNnd6xbVI5cvF7SjeU17AP8VUf9eNOy7+v62FdMZw0ZrEsgjgdt79K5oATb+zsXAefYPnTU\ndqs9b0AC/sn2v43ax7sm0NbJwEG2L5N0OLBnxzqP2tZl38fY7gzYSNpuAvuOaaQpR9alNBH9+DXw\nIknPhOpk5pJ2AK4BtpP0jLLdoeM8fzFwdHnuTEmbAvdRZbsjzgaO6Kg9P0XSk4CfAwdJ2kDSLKoy\nSC+zgGXlKihvHLXudZJmlD4/Hbi27Pvosj2SdignbI+Ga8pgXTLi6Mn27SWzPFXSemXxB21fJ+ko\n4PuSHqAqbcwao4ljgQWSjgRWAUfbPl/SL8v0sB+UOvGzgfNLRv4nqrPQXSzpm8BlwArgwj66/CHg\nAuD28rOzT38AfkN1dZS3l1OR/jtV7fhiVTu/HTiov99OxOBkj/6mFhHRfLvtPs/nnd/P5/bYNlpv\nxkW2501il8aVjDgi2qsZJeIE4ohorwzWRUREX1IjjohWkvRDYPYATay0ve9k9aebBOKIiJqlNBER\nUbME4oiImiUQR0TULIE4IqJmCcQRETVLII6IqFkCcUREzRKIIyJqlkAcEVGz/wfW6imuD/AfnAAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2628e1a37f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed: 78.1min\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed: 117.1min\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed: 194.8min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed: 234.4min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed: 350.5min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 426.3min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed: 519.1min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed: 570.5min\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed: 634.7min\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed: 695.6min\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed: 751.4min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 811.6min\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed: 869.8min\n",
      "[Parallel(n_jobs=4)]: Done 160 out of 160 | elapsed: 1511.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "0.79398922842\n",
      "\n",
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_class_weight', 'param_gamma', 'param_kernel', 'params', 'split0_test_f1_weighted', 'split1_test_f1_weighted', 'split2_test_f1_weighted', 'split3_test_f1_weighted', 'split4_test_f1_weighted', 'mean_test_f1_weighted', 'std_test_f1_weighted', 'rank_test_f1_weighted', 'split0_train_f1_weighted', 'split1_train_f1_weighted', 'split2_train_f1_weighted', 'split3_train_f1_weighted', 'split4_train_f1_weighted', 'mean_train_f1_weighted', 'std_train_f1_weighted', 'split0_test_accuracy', 'split1_test_accuracy', 'split2_test_accuracy', 'split3_test_accuracy', 'split4_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy', 'split0_train_accuracy', 'split1_train_accuracy', 'split2_train_accuracy', 'split3_train_accuracy', 'split4_train_accuracy', 'mean_train_accuracy', 'std_train_accuracy', 'split0_test_precision_weighted', 'split1_test_precision_weighted', 'split2_test_precision_weighted', 'split3_test_precision_weighted', 'split4_test_precision_weighted', 'mean_test_precision_weighted', 'std_test_precision_weighted', 'rank_test_precision_weighted', 'split0_train_precision_weighted', 'split1_train_precision_weighted', 'split2_train_precision_weighted', 'split3_train_precision_weighted', 'split4_train_precision_weighted', 'mean_train_precision_weighted', 'std_train_precision_weighted', 'split0_test_recall_weighted', 'split1_test_recall_weighted', 'split2_test_recall_weighted', 'split3_test_recall_weighted', 'split4_test_recall_weighted', 'mean_test_recall_weighted', 'std_test_recall_weighted', 'rank_test_recall_weighted', 'split0_train_recall_weighted', 'split1_train_recall_weighted', 'split2_train_recall_weighted', 'split3_train_recall_weighted', 'split4_train_recall_weighted', 'mean_train_recall_weighted', 'std_train_recall_weighted'])\n",
      "0.677 (+/-0.473) for {'C': 0.001, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.677 (+/-0.473) for {'C': 0.001, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.677 (+/-0.473) for {'C': 0.001, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.677 (+/-0.473) for {'C': 0.001, 'class_weight': 'balanced', 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.205 (+/-0.000) for {'C': 0.01, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.205 (+/-0.000) for {'C': 0.01, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.241 (+/-0.084) for {'C': 0.01, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.205 (+/-0.000) for {'C': 0.01, 'class_weight': 'balanced', 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.607 (+/-0.211) for {'C': 0.1, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.205 (+/-0.000) for {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.680 (+/-0.176) for {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.490 (+/-0.308) for {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.721 (+/-0.174) for {'C': 1.0, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.795 (+/-0.000) for {'C': 1.0, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.779 (+/-0.117) for {'C': 1.0, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.689 (+/-0.171) for {'C': 1.0, 'class_weight': 'balanced', 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.721 (+/-0.174) for {'C': 1, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.795 (+/-0.000) for {'C': 1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.779 (+/-0.117) for {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.689 (+/-0.171) for {'C': 1, 'class_weight': 'balanced', 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.791 (+/-0.103) for {'C': 10, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.795 (+/-0.000) for {'C': 10, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.046) for {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.128) for {'C': 10, 'class_weight': 'balanced', 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.793 (+/-0.078) for {'C': 50, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.795 (+/-0.000) for {'C': 50, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.067) for {'C': 50, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.795 (+/-0.083) for {'C': 50, 'class_weight': 'balanced', 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.785 (+/-0.080) for {'C': 100, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.795 (+/-0.000) for {'C': 100, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.781 (+/-0.069) for {'C': 100, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.791 (+/-0.079) for {'C': 100, 'class_weight': 'balanced', 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.82      0.86      2024\n",
      "          1       0.50      0.70      0.58       525\n",
      "\n",
      "avg / total       0.83      0.79      0.80      2549\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.82      0.86      2024\n",
      "          1       0.50      0.70      0.58       525\n",
      "\n",
      "avg / total       0.83      0.79      0.80      2549\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[ 81.62  18.38]\n",
      " [ 29.9   70.1 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAFgCAYAAADgjFEzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWc0cWM3MaubAamZWMwdWM7Oa/Q+kLGQdacQ+rQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2628e1c7518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed: 30.4min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 32.3min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed: 34.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "0.735600592428\n",
      "\n",
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_bootstrap', 'param_criterion', 'param_max_depth', 'param_max_features', 'param_n_estimators', 'params', 'split0_test_f1_weighted', 'split1_test_f1_weighted', 'split2_test_f1_weighted', 'split3_test_f1_weighted', 'split4_test_f1_weighted', 'mean_test_f1_weighted', 'std_test_f1_weighted', 'rank_test_f1_weighted', 'split0_train_f1_weighted', 'split1_train_f1_weighted', 'split2_train_f1_weighted', 'split3_train_f1_weighted', 'split4_train_f1_weighted', 'mean_train_f1_weighted', 'std_train_f1_weighted', 'split0_test_accuracy', 'split1_test_accuracy', 'split2_test_accuracy', 'split3_test_accuracy', 'split4_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy', 'split0_train_accuracy', 'split1_train_accuracy', 'split2_train_accuracy', 'split3_train_accuracy', 'split4_train_accuracy', 'mean_train_accuracy', 'std_train_accuracy', 'split0_test_precision_weighted', 'split1_test_precision_weighted', 'split2_test_precision_weighted', 'split3_test_precision_weighted', 'split4_test_precision_weighted', 'mean_test_precision_weighted', 'std_test_precision_weighted', 'rank_test_precision_weighted', 'split0_train_precision_weighted', 'split1_train_precision_weighted', 'split2_train_precision_weighted', 'split3_train_precision_weighted', 'split4_train_precision_weighted', 'mean_train_precision_weighted', 'std_train_precision_weighted', 'split0_test_recall_weighted', 'split1_test_recall_weighted', 'split2_test_recall_weighted', 'split3_test_recall_weighted', 'split4_test_recall_weighted', 'mean_test_recall_weighted', 'std_test_recall_weighted', 'rank_test_recall_weighted', 'split0_train_recall_weighted', 'split1_train_recall_weighted', 'split2_train_recall_weighted', 'split3_train_recall_weighted', 'split4_train_recall_weighted', 'mean_train_recall_weighted', 'std_train_recall_weighted'])\n",
      "0.790 (+/-0.042) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 10}\n",
      "0.788 (+/-0.037) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 20}\n",
      "0.793 (+/-0.009) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 50}\n",
      "0.793 (+/-0.006) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.794 (+/-0.010) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.790 (+/-0.008) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.791 (+/-0.014) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 20}\n",
      "0.796 (+/-0.006) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 50}\n",
      "0.795 (+/-0.002) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.795 (+/-0.004) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 200}\n",
      "0.794 (+/-0.014) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 10}\n",
      "0.792 (+/-0.008) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 20}\n",
      "0.796 (+/-0.009) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 50}\n",
      "0.796 (+/-0.008) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.791 (+/-0.008) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.791 (+/-0.012) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.796 (+/-0.008) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 20}\n",
      "0.794 (+/-0.010) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 50}\n",
      "0.794 (+/-0.003) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.795 (+/-0.005) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 200}\n",
      "0.781 (+/-0.040) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 10}\n",
      "0.794 (+/-0.022) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 20}\n",
      "0.795 (+/-0.010) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 50}\n",
      "0.795 (+/-0.019) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.796 (+/-0.008) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.790 (+/-0.022) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.793 (+/-0.009) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 20}\n",
      "0.793 (+/-0.011) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 50}\n",
      "0.794 (+/-0.006) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.794 (+/-0.004) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 200}\n",
      "0.791 (+/-0.024) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 10}\n",
      "0.792 (+/-0.017) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 20}\n",
      "0.795 (+/-0.013) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 50}\n",
      "0.796 (+/-0.013) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.796 (+/-0.013) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.790 (+/-0.008) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.796 (+/-0.006) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 20}\n",
      "0.794 (+/-0.005) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 50}\n",
      "0.794 (+/-0.008) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.794 (+/-0.007) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 200}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.98      0.89      2024\n",
      "          1       0.61      0.14      0.22       525\n",
      "\n",
      "avg / total       0.77      0.80      0.75      2549\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.98      0.89      2024\n",
      "          1       0.61      0.14      0.22       525\n",
      "\n",
      "avg / total       0.77      0.80      0.75      2549\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[ 97.73   2.27]\n",
      " [ 86.29  13.71]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAFgCAYAAADgjFEzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nybXbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2628e3bd128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed: 82.3min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed: 83.1min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed: 84.3min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 88.9min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed: 120.0min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed: 151.6min\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed: 152.8min\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed: 192.7min\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed: 295.9min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 308.6min\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed: 543.2min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 548.5min\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed: 578.4min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 600.6min\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed: 643.8min\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed: 679.7min\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed: 1531.3min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 1545.2min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit,GroupShuffleSplit\n",
    "from scipy import stats\n",
    "\n",
    "#gss = StratifiedShuffleSplit(n_splits=2, test_size=0.3, random_state=0)\n",
    "gss = GroupShuffleSplit(n_splits=2, test_size=0.3, random_state=0)\n",
    "\n",
    "for train_index, test_index in gss.split(xData, yDataBin, groups=ds['1']):\n",
    "    print(type(train_index), train_index.shape, test_index.shape)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(np.unique(ds.iloc[train_index,1]))\n",
    "    print(np.unique(ds.iloc[test_index,1]))\n",
    "    dt = pd.DataFrame(yDataBin[train_index])\n",
    "    print(dt[0].value_counts())\n",
    "    dte = pd.DataFrame(yDataBin[test_index])\n",
    "    print(dte[0].value_counts())\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    search(xData.iloc[train_index,:], xData.iloc[test_index,:], \n",
    "           yDataBin[train_index], yDataBin[test_index], \n",
    "           ds.iloc[train_index,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(r), len(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(xData, yDataBin, test_size=0.3, random_state=0, stratify=[ds['1'], ds['0']])\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape,\n",
    "      type(X_train.shape), type(X_test.shape), type(y_train.shape), type(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = le.classes_\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "classifier = svm.SVC(kernel='rbf', C=10, gamma=0.01)\n",
    "y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tic = time.clock()\n",
    "y = classifier.predict(X_test[-1:])\n",
    "print(time.clock() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
