{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\n",
      "  python3    C:\\ProgramData\\Anaconda3\\envs\\tf\\share\\jupyter\\kernels\\python3\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\tf\\\\python.exe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'C:\\\\Users\\\\rafae\\\\Downloads\\\\facenet\\\\src',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\tf\\\\python36.zip',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\tf\\\\DLLs',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\tf\\\\lib',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\tf',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\tf\\\\lib\\\\site-packages',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\tf\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\rafae\\\\.ipython']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'C:\\\\Users\\\\rafae\\\\Desktop\\\\Coleta\\\\data\\\\rgb-subset\\\\train'\n",
    "validation_data_dir = 'C:\\\\Users\\\\rafae\\\\Desktop\\\\Coleta\\\\data\\\\rgb-subset\\\\validation'\n",
    "nb_train_samples = 16000\n",
    "nb_validation_samples = 1600\n",
    "epochs = 100\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bottlebeck_features():\n",
    "    print('1')\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        channel_shift_range=0.1)\n",
    "\n",
    "    print('2')\n",
    "    # build the VGG16 network\n",
    "    model = applications.ResNet50(include_top=False, weights='imagenet')\n",
    "\n",
    "    print('3')\n",
    "    generator_train = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        #class_mode=None,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    \n",
    "    print('4')\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator_train, nb_train_samples // batch_size)\n",
    "    \n",
    "    print(bottleneck_features_train.shape)\n",
    "    \n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator_val = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        #class_mode=None,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    \n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator_val, nb_validation_samples // batch_size)\n",
    "    \n",
    "    print(bottleneck_features_validation.shape)\n",
    "    \n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'),\n",
    "            bottleneck_features_validation)\n",
    "    \n",
    "    return bottleneck_features_train, generator_train.classes, bottleneck_features_validation,generator_val.classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_top_model(train_data, train_labels, \n",
    "                    validation_data,validation_labels):\n",
    "    #train_data = np.load(open('bottleneck_features_train.npy','rb'))\n",
    "\n",
    "    #train_labels = np.array(\n",
    "    #    [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "    #validation_data = np.load(open('bottleneck_features_validation.npy','rb'))\n",
    "\n",
    "    train_labels = to_categorical(train_labels, num_classes=3)\n",
    "    validation_labels = to_categorical(validation_labels, num_classes=3)\n",
    "    \n",
    "    print(train_labels.shape, train_data.shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    #model.compile(optimizer='rmsprop',\n",
    "   #               loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "Found 2500 images belonging to 3 classes.\n",
      "4\n",
      "(15928, 1, 1, 2048)\n",
      "Found 560 images belonging to 3 classes.\n",
      "(1600, 1, 1, 2048)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels, validation_data,validation_labels = save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15928, 1, 1, 2048) (2500,) (1600, 1, 1, 2048) (560,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, train_labels.shape, validation_data.shape,validation_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape[0]\n",
    "train_labels_all = np.tile(train_labels, 10)\n",
    "\n",
    "validation_data.shape[0]\n",
    "validation_labels_all = np.tile(validation_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15928, 3) (15928, 1, 1, 2048)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 2,361,347\n",
      "Trainable params: 2,361,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15928 samples, validate on 560 samples\n",
      "Epoch 1/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 1.1049 - acc: 0.3845 - val_loss: 1.0587 - val_acc: 0.4500\n",
      "Epoch 2/100\n",
      "15928/15928 [==============================] - 34s 2ms/step - loss: 1.0515 - acc: 0.4341 - val_loss: 1.0298 - val_acc: 0.4982\n",
      "Epoch 3/100\n",
      "15928/15928 [==============================] - 34s 2ms/step - loss: 1.0339 - acc: 0.4569 - val_loss: 1.0189 - val_acc: 0.5054\n",
      "Epoch 4/100\n",
      "15928/15928 [==============================] - 35s 2ms/step - loss: 1.0132 - acc: 0.4744 - val_loss: 1.0130 - val_acc: 0.3732\n",
      "Epoch 5/100\n",
      "15928/15928 [==============================] - 34s 2ms/step - loss: 1.0007 - acc: 0.4896 - val_loss: 1.0034 - val_acc: 0.5339\n",
      "Epoch 6/100\n",
      "15928/15928 [==============================] - 34s 2ms/step - loss: 0.9925 - acc: 0.4934 - val_loss: 1.1368 - val_acc: 0.3929\n",
      "Epoch 7/100\n",
      "15928/15928 [==============================] - 34s 2ms/step - loss: 0.9821 - acc: 0.5030 - val_loss: 1.0294 - val_acc: 0.3857\n",
      "Epoch 8/100\n",
      "15928/15928 [==============================] - 35s 2ms/step - loss: 0.9805 - acc: 0.5030 - val_loss: 1.0157 - val_acc: 0.4964\n",
      "Epoch 9/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9668 - acc: 0.5151 - val_loss: 0.9713 - val_acc: 0.5232\n",
      "Epoch 10/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9710 - acc: 0.5099 - val_loss: 0.9307 - val_acc: 0.5393\n",
      "Epoch 11/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9663 - acc: 0.5126 - val_loss: 0.9466 - val_acc: 0.5500\n",
      "Epoch 12/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9634 - acc: 0.5155 - val_loss: 0.9579 - val_acc: 0.5589\n",
      "Epoch 13/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9563 - acc: 0.5279 - val_loss: 0.9676 - val_acc: 0.4750\n",
      "Epoch 14/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9542 - acc: 0.5251 - val_loss: 0.9671 - val_acc: 0.5518\n",
      "Epoch 15/100\n",
      "15928/15928 [==============================] - 35s 2ms/step - loss: 0.9578 - acc: 0.5213 - val_loss: 0.9520 - val_acc: 0.5893\n",
      "Epoch 16/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9657 - acc: 0.5115 - val_loss: 1.0256 - val_acc: 0.4804\n",
      "Epoch 17/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9734 - acc: 0.5076 - val_loss: 0.9225 - val_acc: 0.5375\n",
      "Epoch 18/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9622 - acc: 0.5230 - val_loss: 1.0220 - val_acc: 0.4893\n",
      "Epoch 19/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9658 - acc: 0.5055 - val_loss: 0.9164 - val_acc: 0.5982\n",
      "Epoch 20/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9625 - acc: 0.5143 - val_loss: 0.9732 - val_acc: 0.4339\n",
      "Epoch 21/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9643 - acc: 0.5116 - val_loss: 1.0682 - val_acc: 0.4161\n",
      "Epoch 22/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9782 - acc: 0.5070 - val_loss: 1.0647 - val_acc: 0.4339\n",
      "Epoch 23/100\n",
      "15928/15928 [==============================] - 35s 2ms/step - loss: 0.9754 - acc: 0.5043 - val_loss: 0.9656 - val_acc: 0.5268\n",
      "Epoch 24/100\n",
      "15928/15928 [==============================] - 35s 2ms/step - loss: 0.9770 - acc: 0.5062 - val_loss: 1.0205 - val_acc: 0.4821\n",
      "Epoch 25/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9628 - acc: 0.5202 - val_loss: 0.9688 - val_acc: 0.5268\n",
      "Epoch 26/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9701 - acc: 0.5156 - val_loss: 0.9385 - val_acc: 0.5589\n",
      "Epoch 27/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9713 - acc: 0.5094 - val_loss: 0.9256 - val_acc: 0.5750\n",
      "Epoch 28/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9802 - acc: 0.5045 - val_loss: 0.9795 - val_acc: 0.5321\n",
      "Epoch 29/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9829 - acc: 0.4909 - val_loss: 0.9106 - val_acc: 0.5625\n",
      "Epoch 30/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9822 - acc: 0.5040 - val_loss: 0.9624 - val_acc: 0.5268\n",
      "Epoch 31/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9766 - acc: 0.4997 - val_loss: 0.9758 - val_acc: 0.5125\n",
      "Epoch 32/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9837 - acc: 0.5033 - val_loss: 0.9202 - val_acc: 0.5714\n",
      "Epoch 33/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9826 - acc: 0.4967 - val_loss: 0.9303 - val_acc: 0.5696\n",
      "Epoch 34/100\n",
      "15928/15928 [==============================] - 35s 2ms/step - loss: 0.9857 - acc: 0.5033 - val_loss: 0.9029 - val_acc: 0.5732\n",
      "Epoch 35/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9801 - acc: 0.5043 - val_loss: 0.9157 - val_acc: 0.5679\n",
      "Epoch 36/100\n",
      "15928/15928 [==============================] - 35s 2ms/step - loss: 0.9935 - acc: 0.5051 - val_loss: 0.9072 - val_acc: 0.5804\n",
      "Epoch 37/100\n",
      "15928/15928 [==============================] - 35s 2ms/step - loss: 0.9689 - acc: 0.5078 - val_loss: 0.9550 - val_acc: 0.5554\n",
      "Epoch 38/100\n",
      "15928/15928 [==============================] - 35s 2ms/step - loss: 0.9858 - acc: 0.5007 - val_loss: 0.9708 - val_acc: 0.5054\n",
      "Epoch 39/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9929 - acc: 0.5055 - val_loss: 0.9958 - val_acc: 0.4911\n",
      "Epoch 40/100\n",
      "15928/15928 [==============================] - 35s 2ms/step - loss: 0.9867 - acc: 0.4943 - val_loss: 0.9232 - val_acc: 0.5732\n",
      "Epoch 41/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9861 - acc: 0.4901 - val_loss: 0.9760 - val_acc: 0.5250\n",
      "Epoch 42/100\n",
      "15928/15928 [==============================] - 40s 3ms/step - loss: 0.9946 - acc: 0.4938 - val_loss: 0.9845 - val_acc: 0.4982\n",
      "Epoch 43/100\n",
      "15928/15928 [==============================] - 40s 2ms/step - loss: 0.9842 - acc: 0.5068 - val_loss: 0.9617 - val_acc: 0.5321\n",
      "Epoch 44/100\n",
      "15928/15928 [==============================] - 40s 3ms/step - loss: 0.9840 - acc: 0.4996 - val_loss: 1.0168 - val_acc: 0.4625\n",
      "Epoch 45/100\n",
      "15928/15928 [==============================] - 39s 2ms/step - loss: 0.9815 - acc: 0.5005 - val_loss: 0.9933 - val_acc: 0.4839\n",
      "Epoch 46/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9750 - acc: 0.5046 - val_loss: 0.9071 - val_acc: 0.5464\n",
      "Epoch 47/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9854 - acc: 0.5011 - val_loss: 1.0689 - val_acc: 0.4250\n",
      "Epoch 48/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9802 - acc: 0.5041 - val_loss: 0.9025 - val_acc: 0.5804\n",
      "Epoch 49/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9866 - acc: 0.4965 - val_loss: 1.0320 - val_acc: 0.4518\n",
      "Epoch 50/100\n",
      "15928/15928 [==============================] - 41s 3ms/step - loss: 0.9906 - acc: 0.4992 - val_loss: 1.4804 - val_acc: 0.3982\n",
      "Epoch 51/100\n",
      "15928/15928 [==============================] - 39s 2ms/step - loss: 0.9846 - acc: 0.5023 - val_loss: 0.9895 - val_acc: 0.4821\n",
      "Epoch 52/100\n",
      "15928/15928 [==============================] - 41s 3ms/step - loss: 0.9808 - acc: 0.5000 - val_loss: 0.9284 - val_acc: 0.5661\n",
      "Epoch 53/100\n",
      "15928/15928 [==============================] - 40s 3ms/step - loss: 0.9884 - acc: 0.4998 - val_loss: 0.9264 - val_acc: 0.5571\n",
      "Epoch 54/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9935 - acc: 0.4954 - val_loss: 0.9692 - val_acc: 0.5268\n",
      "Epoch 55/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9872 - acc: 0.4913 - val_loss: 0.9661 - val_acc: 0.5125\n",
      "Epoch 56/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9848 - acc: 0.4959 - val_loss: 1.0237 - val_acc: 0.4661\n",
      "Epoch 57/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9813 - acc: 0.4954 - val_loss: 0.9158 - val_acc: 0.5661\n",
      "Epoch 58/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9874 - acc: 0.4949 - val_loss: 0.9360 - val_acc: 0.5554\n",
      "Epoch 59/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9890 - acc: 0.4895 - val_loss: 0.9202 - val_acc: 0.5518\n",
      "Epoch 60/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9951 - acc: 0.4962 - val_loss: 0.9610 - val_acc: 0.5661\n",
      "Epoch 61/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9770 - acc: 0.5019 - val_loss: 0.9460 - val_acc: 0.5446\n",
      "Epoch 62/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9924 - acc: 0.4929 - val_loss: 1.0003 - val_acc: 0.4768\n",
      "Epoch 63/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9724 - acc: 0.5089 - val_loss: 1.0126 - val_acc: 0.4625\n",
      "Epoch 64/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9731 - acc: 0.5055 - val_loss: 0.8959 - val_acc: 0.5946\n",
      "Epoch 65/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9725 - acc: 0.5035 - val_loss: 0.9400 - val_acc: 0.5500\n",
      "Epoch 66/100\n",
      "15928/15928 [==============================] - 35s 2ms/step - loss: 0.9694 - acc: 0.5053 - val_loss: 0.9112 - val_acc: 0.5625\n",
      "Epoch 67/100\n",
      "15928/15928 [==============================] - 35s 2ms/step - loss: 0.9816 - acc: 0.4987 - val_loss: 0.9880 - val_acc: 0.4839\n",
      "Epoch 68/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9767 - acc: 0.5030 - val_loss: 1.0189 - val_acc: 0.4661\n",
      "Epoch 69/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9731 - acc: 0.5048 - val_loss: 0.9896 - val_acc: 0.4839\n",
      "Epoch 70/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9758 - acc: 0.5048 - val_loss: 0.9498 - val_acc: 0.5321\n",
      "Epoch 71/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9746 - acc: 0.5029 - val_loss: 0.9422 - val_acc: 0.5518\n",
      "Epoch 72/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9799 - acc: 0.5031 - val_loss: 0.9797 - val_acc: 0.5107\n",
      "Epoch 73/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9629 - acc: 0.5127 - val_loss: 0.9029 - val_acc: 0.5464\n",
      "Epoch 74/100\n",
      "15928/15928 [==============================] - 42s 3ms/step - loss: 0.9695 - acc: 0.5110 - val_loss: 0.8919 - val_acc: 0.5964\n",
      "Epoch 75/100\n",
      "15928/15928 [==============================] - 41s 3ms/step - loss: 0.9688 - acc: 0.5016 - val_loss: 0.9169 - val_acc: 0.5821\n",
      "Epoch 76/100\n",
      "15928/15928 [==============================] - 39s 2ms/step - loss: 0.9797 - acc: 0.5008 - val_loss: 0.9281 - val_acc: 0.5304\n",
      "Epoch 77/100\n",
      "15928/15928 [==============================] - 45s 3ms/step - loss: 0.9688 - acc: 0.5094 - val_loss: 0.9780 - val_acc: 0.5000\n",
      "Epoch 78/100\n",
      "15928/15928 [==============================] - 40s 3ms/step - loss: 0.9674 - acc: 0.5055 - val_loss: 0.8910 - val_acc: 0.5964\n",
      "Epoch 79/100\n",
      "15928/15928 [==============================] - 39s 2ms/step - loss: 0.9711 - acc: 0.5041 - val_loss: 0.9713 - val_acc: 0.5143\n",
      "Epoch 80/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9703 - acc: 0.5043 - val_loss: 0.9462 - val_acc: 0.5232\n",
      "Epoch 81/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9889 - acc: 0.4955 - val_loss: 1.0103 - val_acc: 0.4696\n",
      "Epoch 82/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9727 - acc: 0.5037 - val_loss: 0.9820 - val_acc: 0.5054\n",
      "Epoch 83/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9771 - acc: 0.4959 - val_loss: 0.9956 - val_acc: 0.4821\n",
      "Epoch 84/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9714 - acc: 0.5016 - val_loss: 0.9817 - val_acc: 0.4857\n",
      "Epoch 85/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9687 - acc: 0.5016 - val_loss: 0.9454 - val_acc: 0.5732\n",
      "Epoch 86/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9916 - acc: 0.4984 - val_loss: 0.9227 - val_acc: 0.5696\n",
      "Epoch 87/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9652 - acc: 0.5087 - val_loss: 0.9200 - val_acc: 0.5839\n",
      "Epoch 88/100\n",
      "15928/15928 [==============================] - 36s 2ms/step - loss: 0.9742 - acc: 0.5017 - val_loss: 0.9924 - val_acc: 0.4982\n",
      "Epoch 89/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9751 - acc: 0.5008 - val_loss: 0.9801 - val_acc: 0.5000\n",
      "Epoch 90/100\n",
      "15928/15928 [==============================] - 37s 2ms/step - loss: 0.9779 - acc: 0.5087 - val_loss: 0.9716 - val_acc: 0.5000\n",
      "Epoch 91/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9810 - acc: 0.5087 - val_loss: 0.9684 - val_acc: 0.5036\n",
      "Epoch 92/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9760 - acc: 0.5116 - val_loss: 0.9319 - val_acc: 0.5679\n",
      "Epoch 93/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9703 - acc: 0.5117 - val_loss: 1.0666 - val_acc: 0.4929\n",
      "Epoch 94/100\n",
      "15928/15928 [==============================] - 39s 2ms/step - loss: 0.9758 - acc: 0.5035 - val_loss: 0.9311 - val_acc: 0.5482\n",
      "Epoch 95/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9647 - acc: 0.5159 - val_loss: 0.9838 - val_acc: 0.5036\n",
      "Epoch 96/100\n",
      "15928/15928 [==============================] - 40s 3ms/step - loss: 0.9715 - acc: 0.5103 - val_loss: 0.9419 - val_acc: 0.5411\n",
      "Epoch 97/100\n",
      "15928/15928 [==============================] - 41s 3ms/step - loss: 0.9744 - acc: 0.5055 - val_loss: 0.9879 - val_acc: 0.4911\n",
      "Epoch 98/100\n",
      "15928/15928 [==============================] - 39s 2ms/step - loss: 0.9781 - acc: 0.5105 - val_loss: 1.0006 - val_acc: 0.4750\n",
      "Epoch 99/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9865 - acc: 0.5070 - val_loss: 0.9724 - val_acc: 0.5143\n",
      "Epoch 100/100\n",
      "15928/15928 [==============================] - 38s 2ms/step - loss: 0.9782 - acc: 0.5057 - val_loss: 0.9946 - val_acc: 0.4982\n"
     ]
    }
   ],
   "source": [
    "train_top_model(train_data, train_labels_all[:train_data.shape[0]], validation_data[:560],validation_labels_all[:560])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    #class_mode=None,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = np.concatenate([generator.next()[0] for i in range(generator.samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator.classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2500//16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "156*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "img_path = 'E:\\\\MestradoData\\\\preprocessed\\\\all\\\\10\\\\41_10_ir1_191.png'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = datetime.datetime.now()\n",
    "model_vgg = applications.VGG16(include_top=False, weights='imagenet')\n",
    "x_vgg_features = model_vgg.predict(x)\n",
    "result = model.predict(x_vgg_features)\n",
    "b = datetime.datetime.now()\n",
    "print(b-a, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
