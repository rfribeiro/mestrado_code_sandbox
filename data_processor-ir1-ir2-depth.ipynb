{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift = 4320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'C:\\\\Users\\\\rafae\\\\Desktop\\\\Coleta\\\\features_hog_*.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "files_list = glob.glob(prefix)\n",
    "print(len(files_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read features\n",
    "frames = [pd.read_csv(f, header=0) for f in files_list ]\n",
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3522, 17282)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17272</th>\n",
       "      <th>17273</th>\n",
       "      <th>17274</th>\n",
       "      <th>17275</th>\n",
       "      <th>17276</th>\n",
       "      <th>17277</th>\n",
       "      <th>17278</th>\n",
       "      <th>17279</th>\n",
       "      <th>17280</th>\n",
       "      <th>17281</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071793</td>\n",
       "      <td>0.090339</td>\n",
       "      <td>0.127822</td>\n",
       "      <td>0.127822</td>\n",
       "      <td>0.042653</td>\n",
       "      <td>0.053141</td>\n",
       "      <td>0.059538</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.019839</td>\n",
       "      <td>0.127822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.030470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021741</td>\n",
       "      <td>0.024379</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.024254</td>\n",
       "      <td>0.051084</td>\n",
       "      <td>0.053452</td>\n",
       "      <td>0.014108</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.119957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.034034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027754</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.028088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103166</td>\n",
       "      <td>0.037546</td>\n",
       "      <td>0.044686</td>\n",
       "      <td>0.122575</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.104095</td>\n",
       "      <td>0.087389</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.017647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.039324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.091092</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.123109</td>\n",
       "      <td>0.038147</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.050142</td>\n",
       "      <td>0.042432</td>\n",
       "      <td>0.028560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>0.010806</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.013665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052366</td>\n",
       "      <td>0.038015</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.061695</td>\n",
       "      <td>0.040908</td>\n",
       "      <td>0.070168</td>\n",
       "      <td>0.032586</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.023819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 17282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1         2         3         4         5         6         7  \\\n",
       "0  1  p002  0.024089  0.000000  0.024089  0.000012  0.024089  0.000000   \n",
       "1  1  p002  0.030470  0.000000  0.030470  0.000000  0.021741  0.024379   \n",
       "2  1  p002  0.034034  0.000000  0.027754  0.015728  0.028088  0.000000   \n",
       "3  1  p002  0.039324  0.000000  0.036597  0.000000  0.017261  0.000000   \n",
       "4  1  p002  0.029356  0.000067  0.029356  0.010806  0.029356  0.000007   \n",
       "\n",
       "          8    9    ...        17272     17273     17274     17275     17276  \\\n",
       "0  0.004740  0.0    ...     0.071793  0.090339  0.127822  0.127822  0.042653   \n",
       "1  0.007708  0.0    ...     0.069514  0.119957  0.119957  0.119957  0.024254   \n",
       "2  0.000000  0.0    ...     0.103166  0.037546  0.044686  0.122575  0.033838   \n",
       "3  0.024395  0.0    ...     0.132490  0.091092  0.132490  0.123109  0.038147   \n",
       "4  0.013665  0.0    ...     0.052366  0.038015  0.034714  0.061695  0.040908   \n",
       "\n",
       "      17277     17278     17279     17280     17281  \n",
       "0  0.053141  0.059538  0.003019  0.019839  0.127822  \n",
       "1  0.051084  0.053452  0.014108  0.010533  0.119957  \n",
       "2  0.104095  0.087389  0.003405  0.009884  0.017647  \n",
       "3  0.132490  0.132490  0.050142  0.042432  0.028560  \n",
       "4  0.070168  0.032586  0.004734  0.009425  0.023819  \n",
       "\n",
       "[5 rows x 17282 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yData = ds['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xData = ds.iloc[:,2:2+shift+shift+shift]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yData.iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3522,) (3522, 12960) <class 'pandas.core.series.Series'> <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(yData.shape, xData.shape, type(yData), type(xData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    plt.yticks(tick_marks)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# Compute confusion matrix\n",
    "def plot_confusion(yTest, yTestPred, name):\n",
    "    cm = confusion_matrix(yTest, yTestPred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Normalize the confusion matrix by row (i.e by the number of samples in each class)\n",
    "    cm_normalized = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis])*100\n",
    "    print('Classification report')\n",
    "    print(classification_report(yTest, yTestPred))\n",
    "    print('Normalized confusion matrix')\n",
    "    print(cm_normalized)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix (%s)' % (name))\n",
    "\n",
    "    plt.show()\n",
    "    # plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer,precision_recall_fscore_support\n",
    "\n",
    "def search(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # normalize data\n",
    "    print(\"Normalizing data!\")\n",
    "    stdScale = preprocessing.StandardScaler().fit(X_train)\n",
    "    xTrain = stdScale.transform(X_train)\n",
    "    xTest = stdScale.transform(X_test)\n",
    "    \n",
    "    print(\"Grid Search Classifiers!\")\n",
    "    \n",
    "    knc = KNeighborsClassifier()\n",
    "    svc = SVC()\n",
    "    rfc = RandomForestClassifier()\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "    clf1 = SVC()\n",
    "    clf2 = RandomForestClassifier(random_state=1)\n",
    "    clf3 = GaussianNB()\n",
    "    vt = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "    kncp = [{'n_neighbors': [3, 5, 7],\n",
    "             'weights': ['uniform','distance'],\n",
    "              'algorithm': ['auto','ball_tree', 'kd_tree', 'brute']}]\n",
    "    svcp = [{'kernel': ['rbf'], #{'kernel': ['rbf','linear'], \n",
    "             'gamma': [0.0001],#'gamma': [1e-3, 1e-4],\n",
    "             'C': [1000]}]#'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 1, 10, 100, 1000]}]\n",
    "    rfcp = [{'n_estimators': [10, 20, 50, 100,200,300], \n",
    "            'max_depth': [None, 1, 10, 100],\n",
    "            'bootstrap': [True, False],\n",
    "            'criterion': [\"gini\", \"entropy\"]}]\n",
    "    gbp = [{#'loss' : ['deviance', 'exponential'],\n",
    "           'n_estimators': [50,100],\n",
    "           'learning_rate': [0.1,1.0,10],\n",
    "           'max_depth' : [3,5,10]\n",
    "            }]\n",
    "           #'min_impurity_decrease': [0.0]}]#, 0.1]}]\n",
    "    vtp = [{'svc__C': [1.0, 100.0], \n",
    "            'rf__n_estimators': [20, 200],}]\n",
    "   \n",
    "    classifiers = [#('kNN', knc, kncp),                                 \n",
    "                    ('Support Vector', svc, svcp),\n",
    "                    #('Random Forest', rfc, rfcp),\n",
    "                    #('Gradient Boosting', gb, gbp),\n",
    "                    #('Vooting', vt, vtp)\n",
    "    ]\n",
    "    \n",
    "    for name, classifier, params in classifiers:\n",
    "        print(name)\n",
    "        clf = GridSearchCV(classifier, params, cv=2, scoring=['f1_weighted','accuracy','precision_weighted', 'recall_weighted'], refit='f1_weighted' , verbose = 10)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print(clf.best_score_)\n",
    "        print()\n",
    "        print(clf.cv_results_.keys())\n",
    "        #means = clf.cv_results_['mean_test_score']\n",
    "        #stds = clf.cv_results_['std_test_score']\n",
    "        #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        #          % (mean, std * 2, params))\n",
    "        #print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        yTrue, yPred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(yTrue, yPred))\n",
    "        plot_confusion(yTrue, yPred, name)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(yData)\n",
    "print(le.classes_)\n",
    "yDataBin = le.transform(yData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2465, 12960) (1057, 12960) (2465,) (1057,) <class 'tuple'> <class 'tuple'> <class 'tuple'> <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(xData, yDataBin, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape,\n",
    "      type(X_train.shape), type(X_test.shape), type(y_train.shape), type(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing data!\n",
      "Grid Search Classifiers!\n",
      "Support Vector\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, f1_weighted=0.7310451352337768, accuracy=0.72859450726979, precision_weighted=0.7514525953487794, recall_weighted=0.72859450726979, total= 3.3min\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, f1_weighted=0.749705625541919, accuracy=0.7473512632436837, precision_weighted=0.7636761690643527, recall_weighted=0.7473512632436837, total= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 10.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 10.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "0.740333744405\n",
      "\n",
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'param_kernel', 'params', 'split0_test_f1_weighted', 'split1_test_f1_weighted', 'mean_test_f1_weighted', 'std_test_f1_weighted', 'rank_test_f1_weighted', 'split0_train_f1_weighted', 'split1_train_f1_weighted', 'mean_train_f1_weighted', 'std_train_f1_weighted', 'split0_test_accuracy', 'split1_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy', 'split0_train_accuracy', 'split1_train_accuracy', 'mean_train_accuracy', 'std_train_accuracy', 'split0_test_precision_weighted', 'split1_test_precision_weighted', 'mean_test_precision_weighted', 'std_test_precision_weighted', 'rank_test_precision_weighted', 'split0_train_precision_weighted', 'split1_train_precision_weighted', 'mean_train_precision_weighted', 'std_train_precision_weighted', 'split0_test_recall_weighted', 'split1_test_recall_weighted', 'mean_test_recall_weighted', 'std_test_recall_weighted', 'rank_test_recall_weighted', 'split0_train_recall_weighted', 'split1_train_recall_weighted', 'mean_train_recall_weighted', 'std_train_recall_weighted'])\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.84      0.89        80\n",
      "          1       0.88      0.91      0.90        57\n",
      "          2       0.96      0.98      0.97        51\n",
      "          3       0.96      0.77      0.86        66\n",
      "          4       0.54      0.97      0.69        62\n",
      "          5       0.86      0.80      0.83        54\n",
      "          6       0.79      0.85      0.82        68\n",
      "          7       0.82      0.75      0.78        65\n",
      "          8       0.85      0.76      0.80        51\n",
      "          9       0.92      0.86      0.89        51\n",
      "         10       0.94      0.87      0.91        55\n",
      "         11       0.84      0.81      0.83        47\n",
      "         12       0.73      0.79      0.76        52\n",
      "         13       0.78      0.86      0.82        44\n",
      "         14       0.78      0.82      0.80        44\n",
      "         15       0.74      0.85      0.79        40\n",
      "         16       0.82      0.79      0.80        52\n",
      "         17       0.92      0.67      0.77        66\n",
      "         18       0.88      0.71      0.79        52\n",
      "\n",
      "avg / total       0.84      0.82      0.83      1057\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.84      0.89        80\n",
      "          1       0.88      0.91      0.90        57\n",
      "          2       0.96      0.98      0.97        51\n",
      "          3       0.96      0.77      0.86        66\n",
      "          4       0.54      0.97      0.69        62\n",
      "          5       0.86      0.80      0.83        54\n",
      "          6       0.79      0.85      0.82        68\n",
      "          7       0.82      0.75      0.78        65\n",
      "          8       0.85      0.76      0.80        51\n",
      "          9       0.92      0.86      0.89        51\n",
      "         10       0.94      0.87      0.91        55\n",
      "         11       0.84      0.81      0.83        47\n",
      "         12       0.73      0.79      0.76        52\n",
      "         13       0.78      0.86      0.82        44\n",
      "         14       0.78      0.82      0.80        44\n",
      "         15       0.74      0.85      0.79        40\n",
      "         16       0.82      0.79      0.80        52\n",
      "         17       0.92      0.67      0.77        66\n",
      "         18       0.88      0.71      0.79        52\n",
      "\n",
      "avg / total       0.84      0.82      0.83      1057\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[ 83.75   8.75   0.     0.     6.25   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     1.25   0.     0.     0.     0.  ]\n",
      " [  7.02  91.23   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     1.75   0.     0.     0.  ]\n",
      " [  0.     0.    98.04   0.     0.     0.     1.96   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.    77.27  12.12   3.03   0.     0.     0.     0.     0.\n",
      "    6.06   0.     1.52   0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.    96.77   3.23   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     1.85  16.67  79.63   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     1.85   0.  ]\n",
      " [  0.     0.     0.     0.     1.47   0.    85.29   8.82   0.     0.     0.\n",
      "    2.94   0.     0.     0.     0.     1.47   0.     0.  ]\n",
      " [  0.     0.     0.     0.     3.08   0.     4.62  75.38   0.     0.     0.\n",
      "    0.     0.     6.15   1.54   0.     4.62   0.     4.62]\n",
      " [  0.     0.     0.     0.     0.     1.96   0.     0.    76.47   0.     0.\n",
      "    0.     9.8    0.     0.     7.84   0.     0.     3.92]\n",
      " [  0.     0.     1.96   0.     0.     0.     0.     0.     0.    86.27\n",
      "    0.     0.     9.8    0.     0.     1.96   0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     1.82   0.     1.82   0.     0.     0.\n",
      "   87.27   0.     0.     1.82   3.64   0.     0.     3.64   0.  ]\n",
      " [  0.     0.     0.     2.13   8.51   2.13   2.13   0.     0.     0.\n",
      "    4.26  80.85   0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     5.77   3.85\n",
      "    0.     0.    78.85   0.     0.    11.54   0.     0.     0.  ]\n",
      " [  0.     0.     2.27   0.     4.55   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.    86.36   0.     0.     6.82   0.     0.  ]\n",
      " [  0.     0.     0.     0.     4.55   2.27   6.82   0.     0.     0.     0.\n",
      "    2.27   0.     0.    81.82   0.     0.     2.27   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     2.5    0.\n",
      "    0.    10.     2.5    0.    85.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     9.62   0.     0.     0.     0.     0.     0.\n",
      "    0.     1.92   7.69   1.92   0.    78.85   0.     0.  ]\n",
      " [  0.     0.     0.     0.    10.61   0.     9.09   1.52   0.     0.\n",
      "    1.52   0.     0.     0.     7.58   0.     3.03  66.67   0.  ]\n",
      " [  0.     0.     0.     0.    11.54   0.     0.     7.69   7.69   1.92\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.    71.15]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAFgCAYAAADgjFEzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA6uZWcUcWM3MKubAamZWsf8PQzV6uYObcwQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a97133a2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(nds.iloc[:,2:])\n",
    "nnds = pca.transform(nds.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
