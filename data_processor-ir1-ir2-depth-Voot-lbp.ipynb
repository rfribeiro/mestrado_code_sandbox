{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift = 4320\n",
    "shift_lbp = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hog_features = 'C:\\\\Users\\\\rafae\\\\Desktop\\\\Coleta\\\\features\\\\features_hog_*.csv'\n",
    "lbp_features = 'C:\\\\Users\\\\rafae\\\\Desktop\\\\Coleta\\\\features\\\\features_lbp_*.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n",
      "235\n"
     ]
    }
   ],
   "source": [
    "hog_files_list = glob.glob(hog_features)\n",
    "print(len(hog_files_list))\n",
    "\n",
    "lbp_files_list = glob.glob(lbp_features)\n",
    "print(len(lbp_files_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read features\n",
    "frames = [pd.read_csv(f, header=0) for f in hog_files_list ]\n",
    "len(frames)\n",
    "\n",
    "# read features\n",
    "lbp = [pd.read_csv(f, header=0) for f in lbp_files_list ]\n",
    "len(lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = pd.concat(frames)\n",
    "ds_lbp = pd.concat(lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3522, 17282) (3522, 132)\n"
     ]
    }
   ],
   "source": [
    "print(ds.shape, ds_lbp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17272</th>\n",
       "      <th>17273</th>\n",
       "      <th>17274</th>\n",
       "      <th>17275</th>\n",
       "      <th>17276</th>\n",
       "      <th>17277</th>\n",
       "      <th>17278</th>\n",
       "      <th>17279</th>\n",
       "      <th>17280</th>\n",
       "      <th>17281</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071793</td>\n",
       "      <td>0.090339</td>\n",
       "      <td>0.127822</td>\n",
       "      <td>0.127822</td>\n",
       "      <td>0.042653</td>\n",
       "      <td>0.053141</td>\n",
       "      <td>0.059538</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.019839</td>\n",
       "      <td>0.127822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.030470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021741</td>\n",
       "      <td>0.024379</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.024254</td>\n",
       "      <td>0.051084</td>\n",
       "      <td>0.053452</td>\n",
       "      <td>0.014108</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.119957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.034034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027754</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.028088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103166</td>\n",
       "      <td>0.037546</td>\n",
       "      <td>0.044686</td>\n",
       "      <td>0.122575</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.104095</td>\n",
       "      <td>0.087389</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.017647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.039324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.091092</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.123109</td>\n",
       "      <td>0.038147</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.050142</td>\n",
       "      <td>0.042432</td>\n",
       "      <td>0.028560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>0.010806</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.013665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052366</td>\n",
       "      <td>0.038015</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.061695</td>\n",
       "      <td>0.040908</td>\n",
       "      <td>0.070168</td>\n",
       "      <td>0.032586</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.023819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1         2         3         4         5         6         7  \\\n",
       "0  1  p002  0.024089  0.000000  0.024089  0.000012  0.024089  0.000000   \n",
       "1  1  p002  0.030470  0.000000  0.030470  0.000000  0.021741  0.024379   \n",
       "2  1  p002  0.034034  0.000000  0.027754  0.015728  0.028088  0.000000   \n",
       "3  1  p002  0.039324  0.000000  0.036597  0.000000  0.017261  0.000000   \n",
       "4  1  p002  0.029356  0.000067  0.029356  0.010806  0.029356  0.000007   \n",
       "\n",
       "          8    9    ...        17272     17273     17274     17275     17276  \\\n",
       "0  0.004740  0.0    ...     0.071793  0.090339  0.127822  0.127822  0.042653   \n",
       "1  0.007708  0.0    ...     0.069514  0.119957  0.119957  0.119957  0.024254   \n",
       "2  0.000000  0.0    ...     0.103166  0.037546  0.044686  0.122575  0.033838   \n",
       "3  0.024395  0.0    ...     0.132490  0.091092  0.132490  0.123109  0.038147   \n",
       "4  0.013665  0.0    ...     0.052366  0.038015  0.034714  0.061695  0.040908   \n",
       "\n",
       "      17277     17278     17279     17280     17281  \n",
       "0  0.053141  0.059538  0.003019  0.019839  0.127822  \n",
       "1  0.051084  0.053452  0.014108  0.010533  0.119957  \n",
       "2  0.104095  0.087389  0.003405  0.009884  0.017647  \n",
       "3  0.132490  0.132490  0.050142  0.042432  0.028560  \n",
       "4  0.070168  0.032586  0.004734  0.009425  0.023819  \n",
       "\n",
       "[5 rows x 17282 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.020433</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>0.016281</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.009943</td>\n",
       "      <td>0.016499</td>\n",
       "      <td>0.015406</td>\n",
       "      <td>0.017592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018029</td>\n",
       "      <td>0.021416</td>\n",
       "      <td>0.011691</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.009943</td>\n",
       "      <td>0.013221</td>\n",
       "      <td>0.014751</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>0.235468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.014532</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>0.011910</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.010817</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018466</td>\n",
       "      <td>0.019777</td>\n",
       "      <td>0.011145</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>0.011254</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.010927</td>\n",
       "      <td>0.015188</td>\n",
       "      <td>0.048733</td>\n",
       "      <td>0.236233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.015079</td>\n",
       "      <td>0.011473</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.014314</td>\n",
       "      <td>0.015297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.014969</td>\n",
       "      <td>0.050153</td>\n",
       "      <td>0.231206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.022509</td>\n",
       "      <td>0.014314</td>\n",
       "      <td>0.013549</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.011254</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>0.010162</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019122</td>\n",
       "      <td>0.019777</td>\n",
       "      <td>0.010271</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.011145</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>0.013330</td>\n",
       "      <td>0.052557</td>\n",
       "      <td>0.228475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.015406</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.015953</td>\n",
       "      <td>0.016390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.020323</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>0.015079</td>\n",
       "      <td>0.049934</td>\n",
       "      <td>0.220061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1         2         3         4         5         6         7  \\\n",
       "0  1  p002  0.020433  0.014205  0.016281  0.012566  0.009943  0.016499   \n",
       "1  1  p002  0.017155  0.017155  0.014532  0.013112  0.011910  0.012456   \n",
       "2  1  p002  0.020542  0.015079  0.011473  0.013986  0.012675  0.014095   \n",
       "3  1  p002  0.022509  0.014314  0.013549  0.012456  0.011254  0.011801   \n",
       "4  1  p002  0.019012  0.011364  0.015406  0.012566  0.011364  0.013986   \n",
       "\n",
       "          8         9    ...          122       123       124       125  \\\n",
       "0  0.015406  0.017592    ...     0.018029  0.021416  0.011691  0.012019   \n",
       "1  0.010817  0.012128    ...     0.018466  0.019777  0.011145  0.011582   \n",
       "2  0.014314  0.015297    ...     0.017373  0.018684  0.010490  0.012238   \n",
       "3  0.010162  0.018247    ...     0.019122  0.019777  0.010271  0.012456   \n",
       "4  0.015953  0.016390    ...     0.017373  0.020323  0.012675  0.011364   \n",
       "\n",
       "        126       127       128       129       130       131  \n",
       "0  0.010599  0.009943  0.013221  0.014751  0.045892  0.235468  \n",
       "1  0.011254  0.010599  0.010927  0.015188  0.048733  0.236233  \n",
       "2  0.012456  0.010599  0.012566  0.014969  0.050153  0.231206  \n",
       "3  0.011145  0.010052  0.014642  0.013330  0.052557  0.228475  \n",
       "4  0.012893  0.012019  0.012893  0.015079  0.049934  0.220061  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_lbp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yData = ds['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xData = ds.iloc[:,2:2+shift+shift+shift]\n",
    "xData = pd.concat([ds_lbp.iloc[:,2:2+shift_lbp+shift_lbp], ds.iloc[:,2+shift:2+shift+shift+shift]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yData.iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3522,) (3522, 8692) <class 'pandas.core.series.Series'> <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(yData.shape, xData.shape, type(yData), type(xData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    plt.yticks(tick_marks)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# Compute confusion matrix\n",
    "def plot_confusion(yTest, yTestPred, name):\n",
    "    cm = confusion_matrix(yTest, yTestPred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Normalize the confusion matrix by row (i.e by the number of samples in each class)\n",
    "    cm_normalized = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis])*100\n",
    "    print('Classification report')\n",
    "    print(classification_report(yTest, yTestPred))\n",
    "    print('Normalized confusion matrix')\n",
    "    print(cm_normalized)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix (%s)' % (name))\n",
    "\n",
    "    plt.show()\n",
    "    # plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(yData)\n",
    "print(le.classes_)\n",
    "yDataBin = le.transform(yData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2465, 8692) (1057, 8692) (2465,) (1057,) <class 'tuple'> <class 'tuple'> <class 'tuple'> <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(xData, yDataBin, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape,\n",
    "      type(X_train.shape), type(X_test.shape), type(y_train.shape), type(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A feature selector for scikit-learn's Pipeline class that returns\n",
    "    specified columns from a numpy array.\n",
    "\n",
    "    \"\"\"\n",
    "    data = {'ir1' : [shift_lbp+shift_lbp, shift_lbp+shift_lbp+shift],\n",
    "            'ir2' : [shift_lbp+shift_lbp+shift, shift_lbp+shift_lbp+shift+shift],\n",
    "            'dep' : [0,shift_lbp+shift_lbp],\n",
    "            'rgb' : [1]}\n",
    "    def __init__(self, key):\n",
    "        print(type(key), key)\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        print('fit', X.shape)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        x = X[:, self.data[self.key][0]:self.data[self.key][1]]\n",
    "        print('trans', X.shape, x.shape, self.data[self.key])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer,precision_recall_fscore_support\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def search(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    pipe1 = Pipeline([\n",
    "               ('sel', ColumnSelector(key='ir1')), # use only IR1 features\n",
    "               ('clf', SVC(probability=True, C=100, gamma=0.001, kernel='rbf'))])\n",
    "\n",
    "    pipe2 = Pipeline([\n",
    "               ('sel', ColumnSelector(key='dep')), # use only Depth features\n",
    "               ('clf', SVC(probability=True))])\n",
    "    \n",
    "    pipe3 = Pipeline([\n",
    "               ('sel', ColumnSelector(key='ir2')), # use only IR2 features\n",
    "               ('clf', SVC(probability=True, C=100, gamma=0.001, kernel='rbf'))])\n",
    "\n",
    "    all = Pipeline([\n",
    "                   ('scaler', preprocessing.StandardScaler()),\n",
    "                   ('eclf', VotingClassifier(estimators=[('ir1',pipe1), ('dep',pipe2), ('ir2',pipe3)], voting='soft', weights=[2,1,2]))\n",
    "    ])\n",
    "    parameters = {\n",
    "    #'eclf__ir1__clf__C':(1.0,10,100,1000),\n",
    "    #'eclf__ir1__clf__C':(1.0,10,100,1000),\n",
    "    'eclf__dep__clf__C':(1.0,10,100,1000),\n",
    "    #'eclf__ir2__clf__C':(1.0,10,100,1000)\n",
    "    }\n",
    "    \n",
    "    clf = GridSearchCV(all, parameters, n_jobs=1, cv=2, scoring=['f1_micro','accuracy'], refit='accuracy' , verbose = 10)\n",
    "    #clf = GridSearchCV(classifier, params, cv=2, scoring=['f1_weighted','accuracy','precision_weighted', 'recall_weighted'], refit='f1_weighted' , verbose = 10)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print(clf.best_score_)\n",
    "    print()\n",
    "    print(clf.cv_results_.keys())\n",
    "    means = clf.cv_results_['mean_test_accuracy']\n",
    "    stds = clf.cv_results_['std_test_accuracy']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    yTrue, yPred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(yTrue, yPred))\n",
    "    plot_confusion(yTrue, yPred, \"test\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ir1\n",
      "<class 'str'> dep\n",
      "<class 'str'> ir2\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "<class 'str'> ir1\n",
      "<class 'str'> dep\n",
      "<class 'str'> ir2\n",
      "<class 'str'> ir1\n",
      "<class 'str'> dep\n",
      "<class 'str'> ir2\n",
      "[CV] eclf__dep__clf__C=1.0 ...........................................\n",
      "<class 'str'> ir1\n",
      "fit (1227, 8692)\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "<class 'str'> dep\n",
      "fit (1227, 8692)\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "<class 'str'> ir2\n",
      "fit (1227, 8692)\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "[CV]  eclf__dep__clf__C=1.0, f1_micro=0.8263327948303716, accuracy=0.8263327948303716, total= 3.7min\n",
      "<class 'str'> ir1\n",
      "<class 'str'> dep\n",
      "<class 'str'> ir2\n",
      "[CV] eclf__dep__clf__C=1.0 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ir1\n",
      "fit (1238, 8692)\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "<class 'str'> dep\n",
      "fit (1238, 8692)\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "<class 'str'> ir2\n",
      "fit (1238, 8692)\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "[CV]  eclf__dep__clf__C=1.0, f1_micro=0.8345558272208639, accuracy=0.8345558272208639, total= 3.6min\n",
      "<class 'str'> ir1\n",
      "<class 'str'> dep\n",
      "<class 'str'> ir2\n",
      "[CV] eclf__dep__clf__C=10 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ir1\n",
      "fit (1227, 8692)\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "<class 'str'> dep\n",
      "fit (1227, 8692)\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "<class 'str'> ir2\n",
      "fit (1227, 8692)\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "[CV]  eclf__dep__clf__C=10, f1_micro=0.8368336025848142, accuracy=0.8368336025848142, total= 3.5min\n",
      "<class 'str'> ir1\n",
      "<class 'str'> dep\n",
      "<class 'str'> ir2\n",
      "[CV] eclf__dep__clf__C=10 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 12.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ir1\n",
      "fit (1238, 8692)\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "<class 'str'> dep\n",
      "fit (1238, 8692)\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "<class 'str'> ir2\n",
      "fit (1238, 8692)\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "[CV]  eclf__dep__clf__C=10, f1_micro=0.8459657701711492, accuracy=0.8459657701711492, total= 3.6min\n",
      "<class 'str'> ir1\n",
      "<class 'str'> dep\n",
      "<class 'str'> ir2\n",
      "[CV] eclf__dep__clf__C=100 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 16.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ir1\n",
      "fit (1227, 8692)\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "<class 'str'> dep\n",
      "fit (1227, 8692)\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "<class 'str'> ir2\n",
      "fit (1227, 8692)\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "[CV]  eclf__dep__clf__C=100, f1_micro=0.8376413570274637, accuracy=0.8376413570274637, total= 3.5min\n",
      "<class 'str'> ir1\n",
      "<class 'str'> dep\n",
      "<class 'str'> ir2\n",
      "[CV] eclf__dep__clf__C=100 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 21.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ir1\n",
      "fit (1238, 8692)\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "<class 'str'> dep\n",
      "fit (1238, 8692)\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "<class 'str'> ir2\n",
      "fit (1238, 8692)\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "[CV]  eclf__dep__clf__C=100, f1_micro=0.8459657701711492, accuracy=0.8459657701711492, total= 3.6min\n",
      "<class 'str'> ir1\n",
      "<class 'str'> dep\n",
      "<class 'str'> ir2\n",
      "[CV] eclf__dep__clf__C=1000 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 25.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ir1\n",
      "fit (1227, 8692)\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "<class 'str'> dep\n",
      "fit (1227, 8692)\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "<class 'str'> ir2\n",
      "fit (1227, 8692)\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "[CV]  eclf__dep__clf__C=1000, f1_micro=0.8344103392568659, accuracy=0.8344103392568659, total= 3.5min\n",
      "<class 'str'> ir1\n",
      "<class 'str'> dep\n",
      "<class 'str'> ir2\n",
      "[CV] eclf__dep__clf__C=1000 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 29.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ir1\n",
      "fit (1238, 8692)\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "<class 'str'> dep\n",
      "fit (1238, 8692)\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "<class 'str'> ir2\n",
      "fit (1238, 8692)\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1227, 8692) (1227, 4320) [52, 4372]\n",
      "trans (1227, 8692) (1227, 52) [0, 52]\n",
      "trans (1227, 8692) (1227, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "trans (1238, 8692) (1238, 4320) [52, 4372]\n",
      "trans (1238, 8692) (1238, 52) [0, 52]\n",
      "trans (1238, 8692) (1238, 4320) [4372, 8692]\n",
      "[CV]  eclf__dep__clf__C=1000, f1_micro=0.8435207823960881, accuracy=0.843520782396088, total= 3.6min\n",
      "<class 'str'> ir1\n",
      "<class 'str'> dep\n",
      "<class 'str'> ir2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 33.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 33.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ir1\n",
      "fit (2465, 8692)\n",
      "trans (2465, 8692) (2465, 4320) [52, 4372]\n",
      "<class 'str'> dep\n",
      "fit (2465, 8692)\n",
      "trans (2465, 8692) (2465, 52) [0, 52]\n",
      "<class 'str'> ir2\n",
      "fit (2465, 8692)\n",
      "trans (2465, 8692) (2465, 4320) [4372, 8692]\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'eclf__dep__clf__C': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "0.841784989858\n",
      "\n",
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_eclf__dep__clf__C', 'params', 'split0_test_f1_micro', 'split1_test_f1_micro', 'mean_test_f1_micro', 'std_test_f1_micro', 'rank_test_f1_micro', 'split0_train_f1_micro', 'split1_train_f1_micro', 'mean_train_f1_micro', 'std_train_f1_micro', 'split0_test_accuracy', 'split1_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy', 'split0_train_accuracy', 'split1_train_accuracy', 'mean_train_accuracy', 'std_train_accuracy'])\n",
      "0.830 (+/-0.008) for {'eclf__dep__clf__C': 1.0}\n",
      "0.841 (+/-0.009) for {'eclf__dep__clf__C': 10}\n",
      "0.842 (+/-0.008) for {'eclf__dep__clf__C': 100}\n",
      "0.839 (+/-0.009) for {'eclf__dep__clf__C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "trans (1057, 8692) (1057, 4320) [52, 4372]\n",
      "trans (1057, 8692) (1057, 52) [0, 52]\n",
      "trans (1057, 8692) (1057, 4320) [4372, 8692]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.89      0.92        80\n",
      "          1       0.90      0.96      0.93        57\n",
      "          2       0.96      0.96      0.96        51\n",
      "          3       0.94      0.89      0.91        66\n",
      "          4       0.92      0.98      0.95        62\n",
      "          5       0.91      0.94      0.93        54\n",
      "          6       0.90      0.82      0.86        68\n",
      "          7       0.83      0.89      0.86        65\n",
      "          8       0.92      0.94      0.93        51\n",
      "          9       0.96      0.90      0.93        51\n",
      "         10       0.85      0.96      0.91        55\n",
      "         11       0.93      0.87      0.90        47\n",
      "         12       0.88      0.87      0.87        52\n",
      "         13       0.93      0.98      0.96        44\n",
      "         14       0.93      0.98      0.96        44\n",
      "         15       0.83      0.88      0.85        40\n",
      "         16       0.92      0.94      0.93        52\n",
      "         17       0.94      0.91      0.92        66\n",
      "         18       0.98      0.85      0.91        52\n",
      "\n",
      "avg / total       0.92      0.91      0.91      1057\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.89      0.92        80\n",
      "          1       0.90      0.96      0.93        57\n",
      "          2       0.96      0.96      0.96        51\n",
      "          3       0.94      0.89      0.91        66\n",
      "          4       0.92      0.98      0.95        62\n",
      "          5       0.91      0.94      0.93        54\n",
      "          6       0.90      0.82      0.86        68\n",
      "          7       0.83      0.89      0.86        65\n",
      "          8       0.92      0.94      0.93        51\n",
      "          9       0.96      0.90      0.93        51\n",
      "         10       0.85      0.96      0.91        55\n",
      "         11       0.93      0.87      0.90        47\n",
      "         12       0.88      0.87      0.87        52\n",
      "         13       0.93      0.98      0.96        44\n",
      "         14       0.93      0.98      0.96        44\n",
      "         15       0.83      0.88      0.85        40\n",
      "         16       0.92      0.94      0.93        52\n",
      "         17       0.94      0.91      0.92        66\n",
      "         18       0.98      0.85      0.91        52\n",
      "\n",
      "avg / total       0.92      0.91      0.91      1057\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[ 88.75   7.5    0.     1.25   1.25   0.     0.     0.     1.25   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  3.51  96.49   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.    96.08   0.     0.     0.     0.     0.     0.     1.96\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     1.96]\n",
      " [  0.     0.     0.    89.39   1.52   7.58   0.     0.     0.     0.\n",
      "    1.52   0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     1.61  98.39   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     3.7   94.44   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     1.85   0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.    82.35  13.24   0.     0.\n",
      "    1.47   0.     0.     0.     0.     0.     0.     2.94   0.  ]\n",
      " [  1.54   0.     0.     0.     0.     0.     1.54  89.23   1.54   0.\n",
      "    1.54   3.08   0.     1.54   0.     0.     0.     0.     0.  ]\n",
      " [  1.96   0.     0.     0.     0.     0.     0.     0.    94.12   0.     0.\n",
      "    1.96   0.     0.     1.96   0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.    90.2\n",
      "    1.96   0.     1.96   0.     0.     3.92   0.     1.96   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   96.36   0.     0.     1.82   0.     0.     1.82   0.     0.  ]\n",
      " [  0.     0.     0.     4.26   0.     0.     4.26   0.     0.     0.\n",
      "    2.13  87.23   0.     0.     2.13   0.     0.     0.     0.  ]\n",
      " [  0.     0.     1.92   0.     0.     0.     0.     0.     0.     1.92\n",
      "    0.     0.    86.54   0.     0.     9.62   0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.    97.73   0.     0.     2.27   0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    2.27   0.     0.     0.    97.73   0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.    12.5    0.     0.    87.5    0.     0.     0.  ]\n",
      " [  0.     0.     1.92   0.     0.     0.     0.     0.     1.92   0.     0.\n",
      "    0.     0.     1.92   0.     0.    94.23   0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     3.03   0.     0.     0.\n",
      "    4.55   0.     0.     0.     0.     0.     1.52  90.91   0.  ]\n",
      " [  0.     0.     0.     0.     1.92   0.     1.92   5.77   1.92   0.     0.\n",
      "    0.     0.     0.     0.     0.     1.92   1.92  84.62]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAFgCAYAAACBlHNxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2558fae9898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(nds.iloc[:,2:])\n",
    "nnds = pca.transform(nds.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer,precision_recall_fscore_support\n",
    "\n",
    "def search2(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # normalize data\n",
    "    print(\"Normalizing data!\")\n",
    "    #stdScale = preprocessing.StandardScaler().fit(xTrain)\n",
    "    #xTrain = stdScale.transform(xTrain)\n",
    "    #xTest = stdScale.transform(xTest)\n",
    "    \n",
    "    print(\"Grid Search Classifiers!\")\n",
    "    \n",
    "    knc = KNeighborsClassifier()\n",
    "    svc = SVC()\n",
    "    rfc = RandomForestClassifier()\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "    clf1 = SVC()\n",
    "    clf2 = RandomForestClassifier(random_state=1)\n",
    "    clf3 = GaussianNB()\n",
    "    vt = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "    kncp = [{'n_neighbors': [3, 5, 7],\n",
    "             'weights': ['uniform','distance'],\n",
    "              'algorithm': ['auto','ball_tree', 'kd_tree', 'brute']}]\n",
    "    svcp = [{'kernel': ['rbf','linear'], \n",
    "             'gamma': [1e-3, 1e-4],\n",
    "             'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 1, 10, 100, 1000]}]\n",
    "    rfcp = [{'n_estimators': [10, 20, 50, 100,200,300], \n",
    "            'max_depth': [None, 1, 10, 100],\n",
    "            'bootstrap': [True, False],\n",
    "            'criterion': [\"gini\", \"entropy\"]}]\n",
    "    gbp = [{#'loss' : ['deviance', 'exponential'],\n",
    "           'n_estimators': [50,100],\n",
    "           'learning_rate': [0.1,1.0,10],\n",
    "           'max_depth' : [3,5,10]\n",
    "            }]\n",
    "           #'min_impurity_decrease': [0.0]}]#, 0.1]}]\n",
    "    vtp = [{'svc__C': [1.0, 100.0], \n",
    "            'rf__n_estimators': [20, 200],}]\n",
    "   \n",
    "    classifiers = [#('kNN', knc, kncp),                                 \n",
    "                    #('Support Vector', svc, svcp),\n",
    "                    #('Random Forest', rfc, rfcp),\n",
    "                    ('Gradient Boosting', gb, gbp),\n",
    "                    ('Vooting', vt, vtp)]\n",
    "    \n",
    "    for name, classifier, params in classifiers:\n",
    "        print(name)\n",
    "        clf = GridSearchCV(classifier, params, cv=2, scoring=['f1_weighted','accuracy','precision_weighted', 'recall_weighted'], refit='f1_weighted' , verbose = 10)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print(clf.best_score_)\n",
    "        print()\n",
    "        print(clf.cv_results_.keys())\n",
    "        #means = clf.cv_results_['mean_test_score']\n",
    "        #stds = clf.cv_results_['std_test_score']\n",
    "        #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        #          % (mean, std * 2, params))\n",
    "        #print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        yTrue, yPred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(yTrue, yPred))\n",
    "        plot_confusion(yTrue, yPred, name)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
