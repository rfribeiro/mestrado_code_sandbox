{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\Anaconda3\\envs\\tf_vggface\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "features_train = pd.read_csv('features_train_new.csv')\n",
    "features_val = pd.read_csv('features_val_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>eor</th>\n",
       "      <th>id</th>\n",
       "      <th>point</th>\n",
       "      <th>image</th>\n",
       "      <th>ir1</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1532</th>\n",
       "      <th>1533</th>\n",
       "      <th>1534</th>\n",
       "      <th>1535</th>\n",
       "      <th>1536</th>\n",
       "      <th>1537</th>\n",
       "      <th>1538</th>\n",
       "      <th>1539</th>\n",
       "      <th>eor_logical</th>\n",
       "      <th>point_logical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988739</td>\n",
       "      <td>2.039143</td>\n",
       "      <td>0.248262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191572</td>\n",
       "      <td>9.335439</td>\n",
       "      <td>2.135622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151517</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>101</td>\n",
       "      <td>0.894081</td>\n",
       "      <td>2.578938</td>\n",
       "      <td>0.191407</td>\n",
       "      <td>0.049469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.122820</td>\n",
       "      <td>11.810625</td>\n",
       "      <td>1.903937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.989725</td>\n",
       "      <td>2.077088</td>\n",
       "      <td>0.221179</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.313927</td>\n",
       "      <td>0.533755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.853697</td>\n",
       "      <td>1.508735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382692</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>111</td>\n",
       "      <td>0.886810</td>\n",
       "      <td>2.305444</td>\n",
       "      <td>0.194974</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.246013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.329632</td>\n",
       "      <td>3.481939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472956</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>121</td>\n",
       "      <td>0.752678</td>\n",
       "      <td>2.417488</td>\n",
       "      <td>0.181901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.290691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687830</td>\n",
       "      <td>8.111677</td>\n",
       "      <td>3.262325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.267931</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1543 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  eor  id  point image       ir1         5         6         7  \\\n",
       "0           0    1   1     13     1  0.988739  2.039143  0.248262  0.000000   \n",
       "1           1    1   1     13   101  0.894081  2.578938  0.191407  0.049469   \n",
       "2           2    1   1     13    11  0.989725  2.077088  0.221179  0.001518   \n",
       "3           3    1   1     13   111  0.886810  2.305444  0.194974  0.005231   \n",
       "4           4    1   1     13   121  0.752678  2.417488  0.181901  0.000000   \n",
       "\n",
       "     8      ...            1532      1533      1534       1535      1536  \\\n",
       "0  0.0      ...        0.979391  0.000000  0.191572   9.335439  2.135622   \n",
       "1  0.0      ...        0.721870  0.000000  3.122820  11.810625  1.903937   \n",
       "2  0.0      ...        1.313927  0.533755  0.000000  12.853697  1.508735   \n",
       "3  0.0      ...        1.246013  0.000000  0.000000   9.329632  3.481939   \n",
       "4  0.0      ...        1.290691  0.000000  0.687830   8.111677  3.262325   \n",
       "\n",
       "   1537  1538      1539  eor_logical  point_logical  \n",
       "0   0.0   0.0  0.151517            1             13  \n",
       "1   0.0   0.0  0.008059            1             13  \n",
       "2   0.0   0.0  0.382692            1             13  \n",
       "3   0.0   0.0  0.472956            1             13  \n",
       "4   0.0   0.0  0.267931            1             13  \n",
       "\n",
       "[5 rows x 1543 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train['eor_logical'] = features_train['eor'].astype('category')\n",
    "features_val['eor_logical'] = features_val['eor'].astype('category')\n",
    "\n",
    "features_train['point_logical'] = features_train['point'].astype('category')\n",
    "features_val['point_logical'] = features_val['point'].astype('category')\n",
    "\n",
    "features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10620, 1543) (4304, 1543)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape, features_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = features_train[features_train['eor_logical'] == 1]['eor_logical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7052,)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain = pd.concat([ytrain,ytrain], axis =0)\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.concat([features_train.loc[features_train['eor'] == 1,:].iloc[:,5:512+5], features_train.loc[features_train['eor'] == 1,:].iloc[:,1028:1028+512]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7052, 1024)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_1 = pd.concat([xtrain,xtrain], axis =0)\n",
    "xtrain_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train and val data\n",
    "qtty_neor = {\"1\": 180,\"2\": 400,\"3\" :400, \"4\": 400,\"5\":400,\"6\": 180,\"7\": 180, \\\n",
    "             \"19\": 150,'10': 800, \"11\": 800,\"15\": 700,\"18\": 500,\"9\":700,\"8\": 180}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7094, 1024)\n"
     ]
    }
   ],
   "source": [
    "xtrain_0 = features_train.loc[(features_train['eor_logical'] == 0)]\n",
    "xtrain_0 = pd.concat([xtrain_0.iloc[:,5:512+5], xtrain_0.iloc[:,1028:1028+512]], axis=1)\n",
    "print(xtrain_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xtrain_0 = pd.DataFrame()\n",
    "#for k,v in qtty_neor.items():\n",
    "#    xtrain3 = features_train.loc[(features_train['eor_logical'] == 0) & (features_train['point'] == int(k))]\n",
    "#    print(k,v, xtrain3.shape)\n",
    "    #xtrain3 = xtrain3.sample(n=v)    \n",
    "    #xtrain3 = pd.concat([xtrain3.iloc[:,5:512+5], xtrain3.iloc[:,1028:1028+512]], axis=1)\n",
    "    #xtrain_0 = pd.concat([xtrain_0, xtrain3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.concat([xtrain_1, xtrain_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = pd.concat([ytrain, pd.Series([0]*xtrain_0.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14146, 1024) (14146,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape, ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4304, 1543)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "yval = features_val[features_val['eor_logical'] == 1]['eor_logical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval = pd.concat([features_val.loc[features_val['eor'] == 1,:].iloc[:,5:512+5], features_val.loc[features_val['eor'] == 1,:].iloc[:,1028:1028+512]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(870,) (870, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(yval.shape, xval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train and val data\n",
    "qtty_neor_val = {\"1\": 70,\"2\": 70,\"3\" :70, \"4\": 70,\"5\":70,\"6\": 70,\"7\": 70, \\\n",
    "             \"19\": 70,'10': 150, \"11\": 150,\"15\": 150,\"18\": 150,\"9\":150,\"8\": 80}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3434, 1543)\n",
      "1 70 (240, 1543)\n",
      "11 150 (240, 1543)\n",
      "9 150 (240, 1543)\n",
      "2 70 (240, 1543)\n",
      "8 80 (240, 1543)\n",
      "7 70 (240, 1543)\n",
      "4 70 (240, 1543)\n",
      "19 70 (210, 1543)\n",
      "5 70 (203, 1543)\n",
      "15 150 (210, 1543)\n",
      "3 70 (240, 1543)\n",
      "10 150 (240, 1543)\n",
      "18 150 (210, 1543)\n",
      "6 70 (201, 1543)\n",
      "(1390, 1024)\n"
     ]
    }
   ],
   "source": [
    "xval_0 = pd.DataFrame()\n",
    "\n",
    "print(features_val.loc[(features_val['eor_logical'] == 0)].shape)\n",
    "for k,v in qtty_neor_val.items():\n",
    "    xtrain3 = features_val.loc[(features_val['eor_logical'] == 0) & (features_val['point'] == int(k))]\n",
    "    print(k,v, xtrain3.shape)\n",
    "    xtrain3 = xtrain3.sample(n=v)    \n",
    "    xtrain3 = pd.concat([xtrain3.iloc[:,5:512+5], xtrain3.iloc[:,1028:1028+512]], axis=1)\n",
    "    xval_0 = pd.concat([xval_0, xtrain3])\n",
    "print(xval_0.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval = pd.concat([xval, xval_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "yval = pd.concat([yval, pd.Series([0]*xval_0.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14146, 1024) (14146,) (2260, 1024) (2260,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape, ytrain.shape, xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7094\n",
       "1    7052\n",
       "dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    plt.yticks(tick_marks)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# Compute confusion matrix\n",
    "def plot_confusion(yTest, yTestPred, name):\n",
    "    cm = confusion_matrix(yTest, yTestPred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Normalize the confusion matrix by row (i.e by the number of samples in each class)\n",
    "    cm_normalized = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis])*100\n",
    "    print('Classification report')\n",
    "    print(classification_report(yTest, yTestPred))\n",
    "    print('Normalized confusion matrix')\n",
    "    print(cm_normalized)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix (%s)' % (name))\n",
    "\n",
    "    plt.show()\n",
    "    # plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer,precision_recall_fscore_support\n",
    "\n",
    "def search(X_train, X_test, y_train, y_test, group_data_train = None):\n",
    "    \n",
    "    # normalize data\n",
    "    print(\"Normalizing data!\")\n",
    "    stdScale = preprocessing.StandardScaler().fit(X_train)\n",
    "    xTrain = stdScale.transform(X_train)\n",
    "    xTest = stdScale.transform(X_test)\n",
    "    \n",
    "    print(\"Grid Search Classifiers!\")\n",
    "    \n",
    "    knc = KNeighborsClassifier()\n",
    "    svc = SVC()\n",
    "    rfc = RandomForestClassifier()\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "    clf1 = SVC()\n",
    "    clf2 = RandomForestClassifier(random_state=1)\n",
    "    clf3 = GaussianNB()\n",
    "    vt = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "    kncp = [{'n_neighbors': [3, 5, 7, 10],\n",
    "             'weights': ['uniform','distance'],\n",
    "              'algorithm': ['auto','kd_tree', 'brute']}]\n",
    "    svcp = [{'kernel': ['rbf'], #{'kernel': ['rbf','linear'], \n",
    "             'class_weight':['balanced'],\n",
    "             'gamma': [0.001],# 0.01, 0.001, 0.0001], #'gamma': [0.0001],#\n",
    "             'decision_function_shape':['ovo'],\n",
    "             'C': [1000] }]# 0.01, 0.1, 1.0, 1, 10, 50, 100, 500, 1000]}]#'C': [1000]}]#\n",
    "    rfcp = [{'n_estimators': [10, 20, 50, 100,200], \n",
    "            'max_features': ['auto', 'log2'],\n",
    "            'max_depth': [None],\n",
    "            'bootstrap': [True, False],\n",
    "            'criterion': [\"gini\", \"entropy\"]}]\n",
    "    gbp = [{#'loss' : ['deviance', 'exponential'],\n",
    "           'n_estimators': [10, 50,100, 200],\n",
    "           'learning_rate': [0.001, 0.01, 0.1, 1.0,10],\n",
    "           'max_features': ['auto', 'log2'],\n",
    "           'max_depth' : [3,5,10, 100]\n",
    "            }]\n",
    "           #'min_impurity_decrease': [0.0]}]#, 0.1]}]\n",
    "    vtp = [{'svc__C': [1.0, 100.0], \n",
    "            'rf__n_estimators': [20, 200],}]\n",
    "   \n",
    "    classifiers = [#('kNN', knc, kncp),                                 \n",
    "                    ('Support Vector', svc, svcp),\n",
    "                    #('Random Forest', rfc, rfcp),\n",
    "                    #('Gradient Boosting', gb, gbp),\n",
    "                    #('Vooting', vt, vtp)\n",
    "    ]\n",
    "    \n",
    "    for name, classifier, params in classifiers:\n",
    "        print(name)\n",
    "        clf = GridSearchCV(classifier, params,n_jobs=4, cv=2, scoring=['f1_weighted','accuracy','precision_weighted', 'recall_weighted'], refit='f1_weighted' , verbose = 10)\n",
    "\n",
    "        clf.fit(X_train, y_train)#, groups=group_data_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print(clf.best_score_)\n",
    "        print()\n",
    "        print(clf.cv_results_.keys())\n",
    "        means = clf.cv_results_['mean_test_accuracy']\n",
    "        stds = clf.cv_results_['std_test_accuracy']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        yTrue, yPred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(yTrue, yPred))\n",
    "        plot_confusion(yTrue, yPred, name)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing data!\n",
      "Grid Search Classifiers!\n",
      "Support Vector\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    }
   ],
   "source": [
    "search(xtrain, xval, ytrain, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(xData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xDataPCA = pca.transform(xData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training points\n",
    "plt.scatter(xDataPCA[:, 0], xDataPCA[:, 1], c=y, cmap=plt.cm.Set1,edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
