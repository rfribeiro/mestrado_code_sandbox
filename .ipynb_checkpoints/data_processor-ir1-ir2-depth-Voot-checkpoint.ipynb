{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift = 4320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'C:\\\\Users\\\\rafae\\\\Desktop\\\\Coleta\\\\features_hog_*.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "files_list = glob.glob(prefix)\n",
    "print(len(files_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read features\n",
    "frames = [pd.read_csv(f, header=0) for f in files_list ]\n",
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3522, 17282)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17272</th>\n",
       "      <th>17273</th>\n",
       "      <th>17274</th>\n",
       "      <th>17275</th>\n",
       "      <th>17276</th>\n",
       "      <th>17277</th>\n",
       "      <th>17278</th>\n",
       "      <th>17279</th>\n",
       "      <th>17280</th>\n",
       "      <th>17281</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071793</td>\n",
       "      <td>0.090339</td>\n",
       "      <td>0.127822</td>\n",
       "      <td>0.127822</td>\n",
       "      <td>0.042653</td>\n",
       "      <td>0.053141</td>\n",
       "      <td>0.059538</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.019839</td>\n",
       "      <td>0.127822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.030470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021741</td>\n",
       "      <td>0.024379</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.024254</td>\n",
       "      <td>0.051084</td>\n",
       "      <td>0.053452</td>\n",
       "      <td>0.014108</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.119957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.034034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027754</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.028088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103166</td>\n",
       "      <td>0.037546</td>\n",
       "      <td>0.044686</td>\n",
       "      <td>0.122575</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.104095</td>\n",
       "      <td>0.087389</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.017647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.039324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.091092</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.123109</td>\n",
       "      <td>0.038147</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.050142</td>\n",
       "      <td>0.042432</td>\n",
       "      <td>0.028560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>p002</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>0.010806</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.013665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052366</td>\n",
       "      <td>0.038015</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.061695</td>\n",
       "      <td>0.040908</td>\n",
       "      <td>0.070168</td>\n",
       "      <td>0.032586</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.023819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 17282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1         2         3         4         5         6         7  \\\n",
       "0  1  p002  0.024089  0.000000  0.024089  0.000012  0.024089  0.000000   \n",
       "1  1  p002  0.030470  0.000000  0.030470  0.000000  0.021741  0.024379   \n",
       "2  1  p002  0.034034  0.000000  0.027754  0.015728  0.028088  0.000000   \n",
       "3  1  p002  0.039324  0.000000  0.036597  0.000000  0.017261  0.000000   \n",
       "4  1  p002  0.029356  0.000067  0.029356  0.010806  0.029356  0.000007   \n",
       "\n",
       "          8    9    ...        17272     17273     17274     17275     17276  \\\n",
       "0  0.004740  0.0    ...     0.071793  0.090339  0.127822  0.127822  0.042653   \n",
       "1  0.007708  0.0    ...     0.069514  0.119957  0.119957  0.119957  0.024254   \n",
       "2  0.000000  0.0    ...     0.103166  0.037546  0.044686  0.122575  0.033838   \n",
       "3  0.024395  0.0    ...     0.132490  0.091092  0.132490  0.123109  0.038147   \n",
       "4  0.013665  0.0    ...     0.052366  0.038015  0.034714  0.061695  0.040908   \n",
       "\n",
       "      17277     17278     17279     17280     17281  \n",
       "0  0.053141  0.059538  0.003019  0.019839  0.127822  \n",
       "1  0.051084  0.053452  0.014108  0.010533  0.119957  \n",
       "2  0.104095  0.087389  0.003405  0.009884  0.017647  \n",
       "3  0.132490  0.132490  0.050142  0.042432  0.028560  \n",
       "4  0.070168  0.032586  0.004734  0.009425  0.023819  \n",
       "\n",
       "[5 rows x 17282 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yData = ds['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xData = ds.iloc[:,2:2+shift+shift+shift]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yData.iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3522,) (3522, 12960) <class 'pandas.core.series.Series'> <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(yData.shape, xData.shape, type(yData), type(xData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    plt.yticks(tick_marks)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# Compute confusion matrix\n",
    "def plot_confusion(yTest, yTestPred, name):\n",
    "    cm = confusion_matrix(yTest, yTestPred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Normalize the confusion matrix by row (i.e by the number of samples in each class)\n",
    "    cm_normalized = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis])*100\n",
    "    print('Classification report')\n",
    "    print(classification_report(yTest, yTestPred))\n",
    "    print('Normalized confusion matrix')\n",
    "    print(cm_normalized)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix (%s)' % (name))\n",
    "\n",
    "    plt.show()\n",
    "    # plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnSelector(object):\n",
    "    \"\"\"\n",
    "    A feature selector for scikit-learn's Pipeline class that returns\n",
    "    specified columns from a numpy array.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, start, end):\n",
    "        self.start = start-1\n",
    "        self.end = end\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.start:self.end]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer,precision_recall_fscore_support\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def search(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    pipe1 = Pipeline([\n",
    "               ('sel', ColumnSelector(2+shift, 2+shift+shift)), # use only IR1 features\n",
    "               ('clf', SVC(gamma=0.001, C=100, kernel='rbf'))])\n",
    "\n",
    "    pipe2 = Pipeline([\n",
    "               ('sel', ColumnSelector(2,2+shift)), # use only Depth features\n",
    "               ('clf', SVC(gamma=0.001, C=100, kernel='rbf'))])\n",
    "    \n",
    "    pipe3 = Pipeline([\n",
    "               ('sel', ColumnSelector(2+shift+shift, 2+shift+shift+shift)), # use only IR2 features\n",
    "               ('clf', SVC(gamma=0.001, C=100, kernel='rbf'))])\n",
    "\n",
    "    all = Pipeline([\n",
    "                   ('scaler', preprocessing.StandardScaler()),\n",
    "                   ('eclf', VotingClassifier(estimators=[('ir1',pipe1), ('dep',pipe2), ('ir2',pipe3)], voting='hard'))\n",
    "    ])\n",
    "    parameters = {\n",
    "    #'eclf__clfs__dim__n_components':(1,1),\n",
    "    }\n",
    "    \n",
    "    clf = GridSearchCV(all, parameters, cv=5, scoring=['f1_micro','accuracy'], refit='accuracy' , verbose = 10)\n",
    "    #clf = GridSearchCV(classifier, params, cv=2, scoring=['f1_weighted','accuracy','precision_weighted', 'recall_weighted'], refit='f1_weighted' , verbose = 10)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print(clf.best_score_)\n",
    "    print()\n",
    "    print(clf.cv_results_.keys())\n",
    "    #means = clf.cv_results_['mean_test_score']\n",
    "    #stds = clf.cv_results_['std_test_score']\n",
    "    #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "    #          % (mean, std * 2, params))\n",
    "    #print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    yTrue, yPred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(yTrue, yPred))\n",
    "    plot_confusion(yTrue, yPred, \"test\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(yData)\n",
    "print(le.classes_)\n",
    "yDataBin = le.transform(yData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2465, 12960) (1057, 12960) (2465,) (1057,) <class 'tuple'> <class 'tuple'> <class 'tuple'> <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(xData, yDataBin, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape,\n",
    "      type(X_train.shape), type(X_test.shape), type(y_train.shape), type(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n",
      "[CV]  , f1_micro=0.7955911823647294, accuracy=0.7955911823647295, total= 3.4min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  6.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , f1_micro=0.872983870967742, accuracy=0.8729838709677419, total= 3.5min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 12.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , f1_micro=0.8588709677419355, accuracy=0.8588709677419355, total= 3.4min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 18.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , f1_micro=0.826530612244898, accuracy=0.826530612244898, total= 3.5min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 24.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , f1_micro=0.8450413223140496, accuracy=0.8450413223140496, total= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 31.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 31.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{}\n",
      "\n",
      "Grid scores on development set:\n",
      "0.839756592292\n",
      "\n",
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'params', 'split0_test_f1_micro', 'split1_test_f1_micro', 'split2_test_f1_micro', 'split3_test_f1_micro', 'split4_test_f1_micro', 'mean_test_f1_micro', 'std_test_f1_micro', 'rank_test_f1_micro', 'split0_train_f1_micro', 'split1_train_f1_micro', 'split2_train_f1_micro', 'split3_train_f1_micro', 'split4_train_f1_micro', 'mean_train_f1_micro', 'std_train_f1_micro', 'split0_test_accuracy', 'split1_test_accuracy', 'split2_test_accuracy', 'split3_test_accuracy', 'split4_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy', 'split0_train_accuracy', 'split1_train_accuracy', 'split2_train_accuracy', 'split3_train_accuracy', 'split4_train_accuracy', 'mean_train_accuracy', 'std_train_accuracy'])\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.93      0.67        80\n",
      "          1       0.89      0.89      0.89        57\n",
      "          2       0.98      0.88      0.93        51\n",
      "          3       0.64      0.91      0.75        66\n",
      "          4       0.82      0.98      0.90        62\n",
      "          5       0.85      0.93      0.88        54\n",
      "          6       0.98      0.72      0.83        68\n",
      "          7       0.83      0.83      0.83        65\n",
      "          8       0.98      0.86      0.92        51\n",
      "          9       0.98      0.88      0.93        51\n",
      "         10       0.92      0.89      0.91        55\n",
      "         11       1.00      0.83      0.91        47\n",
      "         12       0.87      0.77      0.82        52\n",
      "         13       0.90      0.86      0.88        44\n",
      "         14       0.97      0.89      0.93        44\n",
      "         15       0.90      0.88      0.89        40\n",
      "         16       0.91      0.83      0.87        52\n",
      "         17       0.95      0.64      0.76        66\n",
      "         18       1.00      0.60      0.75        52\n",
      "\n",
      "avg / total       0.88      0.84      0.85      1057\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-93ab1c96c82e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-d8b9d496c040>\u001b[0m in \u001b[0;36msearch\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0myTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myPred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myPred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mplot_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myPred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(nds.iloc[:,2:])\n",
    "nnds = pca.transform(nds.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer,precision_recall_fscore_support\n",
    "\n",
    "def search2(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # normalize data\n",
    "    print(\"Normalizing data!\")\n",
    "    #stdScale = preprocessing.StandardScaler().fit(xTrain)\n",
    "    #xTrain = stdScale.transform(xTrain)\n",
    "    #xTest = stdScale.transform(xTest)\n",
    "    \n",
    "    print(\"Grid Search Classifiers!\")\n",
    "    \n",
    "    knc = KNeighborsClassifier()\n",
    "    svc = SVC()\n",
    "    rfc = RandomForestClassifier()\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "    clf1 = SVC()\n",
    "    clf2 = RandomForestClassifier(random_state=1)\n",
    "    clf3 = GaussianNB()\n",
    "    vt = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "    kncp = [{'n_neighbors': [3, 5, 7],\n",
    "             'weights': ['uniform','distance'],\n",
    "              'algorithm': ['auto','ball_tree', 'kd_tree', 'brute']}]\n",
    "    svcp = [{'kernel': ['rbf','linear'], \n",
    "             'gamma': [1e-3, 1e-4],\n",
    "             'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 1, 10, 100, 1000]}]\n",
    "    rfcp = [{'n_estimators': [10, 20, 50, 100,200,300], \n",
    "            'max_depth': [None, 1, 10, 100],\n",
    "            'bootstrap': [True, False],\n",
    "            'criterion': [\"gini\", \"entropy\"]}]\n",
    "    gbp = [{#'loss' : ['deviance', 'exponential'],\n",
    "           'n_estimators': [50,100],\n",
    "           'learning_rate': [0.1,1.0,10],\n",
    "           'max_depth' : [3,5,10]\n",
    "            }]\n",
    "           #'min_impurity_decrease': [0.0]}]#, 0.1]}]\n",
    "    vtp = [{'svc__C': [1.0, 100.0], \n",
    "            'rf__n_estimators': [20, 200],}]\n",
    "   \n",
    "    classifiers = [#('kNN', knc, kncp),                                 \n",
    "                    #('Support Vector', svc, svcp),\n",
    "                    #('Random Forest', rfc, rfcp),\n",
    "                    ('Gradient Boosting', gb, gbp),\n",
    "                    ('Vooting', vt, vtp)]\n",
    "    \n",
    "    for name, classifier, params in classifiers:\n",
    "        print(name)\n",
    "        clf = GridSearchCV(classifier, params, cv=2, scoring=['f1_weighted','accuracy','precision_weighted', 'recall_weighted'], refit='f1_weighted' , verbose = 10)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print(clf.best_score_)\n",
    "        print()\n",
    "        print(clf.cv_results_.keys())\n",
    "        #means = clf.cv_results_['mean_test_score']\n",
    "        #stds = clf.cv_results_['std_test_score']\n",
    "        #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        #          % (mean, std * 2, params))\n",
    "        #print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        yTrue, yPred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(yTrue, yPred))\n",
    "        plot_confusion(yTrue, yPred, name)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
